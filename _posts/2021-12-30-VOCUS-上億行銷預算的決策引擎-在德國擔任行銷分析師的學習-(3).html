---
layout: post
title: 上億行銷預算的決策引擎：在德國擔任行銷分析師的學習 (3)
date: 2021-12-30 05:53:06.000000000 +00:00
link: https://vocus.cc/user/@fyhgooi/61cc353bfd89780001f8f7cb
categories: vocus
tags: blog
author: Stevehuang
---

<p>前導連結</p>
<p><a href="https://vocus.cc/one-minute-germany/61c1f5e2fd89780001c900ae">上億行銷預算的決策引擎：在德國擔任行銷分析師的學習(1) - MTA行銷歸因</a></p>
<p><a href="https://vocus.cc/article/61c2fd98fd89780001f4fccf">上億行銷預算的決策引擎：在德國擔任行銷分析師的學習(2) - MMM行銷組合</a></p>
<p><br></p>
<p>在前面兩篇的討論中，身為行銷分析人員的我們終於對於行銷績效有點理解了，但千辛萬苦地把模型跟報表建立起來後，把結果呈現到行銷主管面前時，一定會被問：你有信心這個數字是對的嗎？我如果聽你的建議，我會在電視廣告多下1千萬，你有信心他會回本？</p>
<p>其實這件事情真的很難說的準，沒有人真的知道真實世界的全貌，任何預測模型都必定有偏誤，最常遇到的是統計模型的結果跟商業直覺，或是過去的方法結果差異很多，那我們要怎麼去檢證跟溝通？</p>
<h2>統計準確性跟業務經驗的攻防</h2>
<p>統計常用的檢證方式，是做任何數據模型都相當好用的工具，例如顯著性(Significance)越高越好，代表訊號越明確，判定係數(R-Square)越高越好，代表模型解釋力很高，絕對百分比誤差(MAPE)越小越好，代表預測的準確度越高。這些統計檢證通常讓我們比較有辦法跟決策端溝通：至少在統計上，這個模型的預測力如何，以及我們有多少的信心說出這個結論</p>
<p><br></p>
<p>但就算我端出一個統計檢證完美，邏輯縝密的模型，大家會相信嗎？經濟學人曾經做過一個調查報告，指出大多數的管理層看到跟自己經驗不符的數據時，他們會大力挑戰，很多時候會找替代的分析方式來做出自己比較能接受的結果，我自己的經驗是，當分析結果管理層的利益有潛在衝突時，會更容易被挑戰</p>
<h2>那不如做個實驗吧？我們要的不是相關性，而是因果關係</h2>
<p>「做了才知道」通常是解決大家疑慮的最後手段，畢竟大多數的統計模型都在講相關性，而非因果關係，只有實際做了才知道有什麼結果。但是，躁進的丟入上百萬的預算，或是砍掉一整個部門都不是縝密決策的方式，更不可能有主管答應你這麼做</p>
<p>「做個實驗吧？」是近十年來蠻常見的做法，電子商務來說，跟一些主要的廣告投放平台例如Google，Facebook合作，都可以進行實驗設計跟分析，大致來說有幾大步驟：</p>
<p><br></p>
<h3>1. 設想實驗目標</h3>
<p>與行銷分析相關的實驗通常和預算有關，像是：我想知道在法國多花100萬在Youtube是不是會維持一樣的投資報酬率？我想知道把品牌關鍵字廣告減少一半的預算是不是可以靠關鍵字搜尋補上？廣播，電視這些傳統媒體還要再投嗎，要投多少？</p>
<h3>2. 設計實驗</h3>
<p>針對不同實驗的客群或地區，哪些地區/客群應該被選為實驗組，哪些應該被選為對照組，例如Google就有推出以郵遞區號為基礎的Geo-Based實驗單位，搭配上企業過去在各區域的業績，就可以稍微計算出哪些適合當實驗組，哪些適合當對照組</p>
<p>有些傳統媒體不允許小地區投放，那該怎麼做實驗呢？以美國為例可以用“州“為單位，德國以“邦”為單位，跨國企業甚至可以用“國“為單位來進行實驗</p>
<p>有幾個簡要的原則：</p>
<ul>
  <li><strong>實驗組跟對照組越多，越能有深入的結果</strong></li>
  <li><strong>實驗越大（投入越多或是刪減預算越多），越容易讀取有效的訊號</strong></li>
  <li><strong>實驗單位越大，環境的雜訊越多，實驗的準確性越低</strong></li>
</ul>
<p><br></p>
<h3>3. 實驗分析</h3>
<p>如果在實驗室裡面做實驗，通常的想像是：實驗組跟對照組在實驗之前沒有差別，實驗開始後，我們會看到實驗組的改變，實驗組跟對照組的成果就是實驗的結果</p>
<p>在現實世界裡的實驗要達到這個條件相當困難，例如「實驗組跟對照組在實驗之前沒有差別」，沒有差別是在業績上，毛利上或是顧客轉化率沒有差別？是過去三個月，過去六個月沒有差別？是成長率，季節波動都一致？</p>
<p>「在實驗之後實驗組跟對照組的差異」這差異要怎麼讀？看起來若有似無的差異在統計上有沒有顯著？我要算一個月，兩個月，三個月？有沒有遞延效應？是每一個實驗組都有相似的表現，還是有些沒有？我最後又該怎麼計算投資報酬率？</p>
<p>市面上有蠻多分析方法，例如Google就有推出一些模組讓分析師去套用，把上述的假設跟條件都想好之後，就能進行分析了</p>
<p>延伸資源：<a href="https://google.github.io/CausalImpact/CausalImpact.html">Google Causal Impact R - Package, Baysian Model Structural Time Series</a></p>
<h3>4. 把實驗分析的結果丟回原有的模型</h3>
<p>分析做完之後，我們就可以把實驗的結果當成真實的情況，運用這個結果來修正原本的MMM（行銷組合模型），把實驗的數據轉化成模型裡的參數，例如說：電視廣告的實驗結果顯示，投資報酬率是3，但原本的MMM模型算出來是5，那我就可以用3當成一個參考值來訓練模型</p>
<p>實驗也可用來調整模型中的商業假設，例如實驗結果顯示，Youtube的長尾效應大概只有兩週，而且逐日遞減，那我也可以拿來修正MMM裡面長尾效應的參數，實驗做得越多元，就越能理解不同行銷活動在不同市場，不同通路，不同預算下的投資報酬率，就可以讓行銷組合模型越來越貼近現實</p>
<p>即使實驗是個很棒的驗證方式，卻也不是定海神針，一個設計不良，分析不縝密的實驗的結果並不值得信賴，要能讀到有效的結果，實驗的成本也不低，要能大量，快速進行實驗更是非常困難，需要很成熟的分析量能還有密集的協調溝通，適用的企業，市場都相對限縮</p>
<h2>在績效數字背後，是一群人努力的結果</h2>
<p><br></p>
<p>在數據科學上我們有很多的工具，來剖析行銷人心中的蝴蝶效應，幫助決策者把錢花在更有效的地方，但如果你也在做行銷分析，請把這句話記在心裡，<strong>「在績效數字背後，是一群人努力的結果」</strong></p>
<p>每個行銷活動都是行銷部門規劃數個月甚至多年的心血，當我們在某部門的行銷主管面前說：“去年你們行銷活動的投資報酬率根本不到1，所以我們不建議明年再投入任何預算”，不管是真是假，你的分析方法都不會得到他們的信任，他們更會窮盡方法挑戰你模型中的每一個假設，提出大量市場報告來反駁你的結論，因為他需要保住他的預算，團隊甚至工作</p>
<p>在過去幾年的經驗裡，我發現行銷分析的工作更多在於溝通，讓越多行銷人員可以參與，分享不同分析觀點，接納不同的假設，驗證再修正分析成果，在統計效度跟商業經驗中作平衡，這樣的分析團隊也才能被信任，慢慢地行銷分析的結果就能變成決策的基礎</p>
<p><a href="https://vocus.cc/one-minute-germany/61897dcbfd89780001eaa914"><strong>延伸閱讀：在商業分析師的工作裡，人比數字更重要</strong></a></p>
<p><br></p>
<p><strong>感謝你的閱讀，喜歡這篇文章的話歡迎幫我們點讚分享，訂閱我們的專題喔!</strong></p>
<p><br></p>
