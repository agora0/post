---
layout: post
title: 請看懂智慧的本質：GTP4的「人工通用智能」（AGI）落後人類有多遠？─學習的本質（22）
date: 2023-04-16 00:00:01.000000000 +00:00
link: https://vocus.cc/article/643b3a81fd89780001778127
categories: vocus
tags: blog
author: 陳華夫hwafuchen
---

<div class="draft-block draft--p left">作者：陳華夫</div>
<div class="draft-block draft--p left"><a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>（AI）近年進步神速，2017年<a href="https://www.google.com.tw/" target="_blank" class="draft--a">谷歌</a>（Google）的<a href="https://zh.wikipedia.org/wiki/DeepMind" target="_blank" class="draft--a">DeepMind</a>公司推出超級電腦圍棋 <a href="https://zh.wikipedia.org/wiki/AlphaGo_Zero" target="_blank" class="draft--a">AlphaGo Zero</a>，棋力遠遠超過人類。2022年<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>公司推出<a href="https://zh.wikipedia.org/zh-tw/ChatGPT" target="_blank" class="draft--a">ChatGPT</a>聊天機器人（<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>版本），它的<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）<a href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1" target="_blank" class="draft--a">神經網路</a>包含175G參數，800GB<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token），其訓練數據庫基本上是數十萬篇英文學術論文、新聞報導、書籍和社群媒體貼文。它雖然沒有人類<a href="https://zh.wikipedia.org/zh-tw/%E6%84%8F%E8%AF%86" target="_blank" class="draft--a">意識</a>的<a href="https://en.wikipedia.org/wiki/Teleonomy" target="_blank" class="draft--a">目的性</a>，但它擁有接近人類水平的<a href="https://zh.wikipedia.org/zh-tw/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86" target="_blank" class="draft--a">自然語言處理</a>（NLP）能力及對話<a href="https://zh.wikipedia.org/zh-tw/%E9%80%BB%E8%BE%91" target="_blank" class="draft--a">邏輯</a>。</div>
<div class="draft-block draft--p left">但更令人震撼的是，<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>公司2023/3/15發佈了其最新的<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)之<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>，在美國律師資格考試、大學先修考試和SAT學校考試等多項學術和專業基準考試中遠超過<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>，達到傑出人類的水平。（見<a href="http://big5.ftchinese.com/interactive/101407?exclusive" target="_blank" class="draft--a">GPT製造商OpenAI推出新模型GPT-4</a>）</div>
<div class="draft-block draft--p left"><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>具有推理、創造力和演繹等核心心智能力，並在文學、醫學和編碼等一系列主題方面獲得了專業知識。並且可以執行各種任務，例如玩遊戲、使用工具和自我解釋顯示出了<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的火花，也引起人們的恐慌；美國富豪<a href="https://zh.wikipedia.org/zh-tw/%E5%9F%83%E9%9A%86%C2%B7%E9%A9%AC%E6%96%AF%E5%85%8B" target="_blank" class="draft--a">馬斯克</a>及其他<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>專家、業界高管在一封公開信中表示，考量對社會及人類的潛在風險，呼籲未來6個月先暫停對優於<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>系統進行訓練。（見<a href="https://tw.sports.yahoo.com/news/%E9%A6%AC%E6%96%AF%E5%85%8B%E7%AD%89%E5%8D%83%E4%BA%BA%E9%80%A3%E7%BD%B2%E7%96%BE%E5%91%BC-%E6%9A%AB%E5%81%9C%E8%A8%93%E7%B7%B4%E5%84%AA%E6%96%BCgpt-4%E7%9A%84ai%E7%B3%BB%E7%B5%B1-084454887.html" target="_blank" class="draft--a">馬斯克等千人連署疾呼 暫停訓練優於GPT-4的AI系統</a>）</div>
<div class="draft-block draft--p left">但媒體上有關<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的報導大都誇大不實。<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>（<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>的母公司）的工程師團隊們在2023/3/22發表了研究論文：〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通用人工智能的火花：GPT-4的早期實驗</a>〉（2023），1-155頁，以下簡稱〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉)，試圖釐清<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>所具有的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）之局限性，並且討論了更深入和更全面的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）所面臨的挑戰，包括需要超越<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">小樣本提示</a>與<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">零樣本提示</a>的詞語預測之新範式:</div>
<figure class="draft--imgNormal draft-block"><div><img data-src="https://images.vocus.cc/24aa60d8-36c3-4734-bee3-99500caff8ed.jpg" data-width="1520" data-height="1145" data-position="center" src="https://images.vocus.cc/24aa60d8-36c3-4734-bee3-99500caff8ed.jpg" referrerpolicy="no-referrer"><figcaption class="imageCaption draft-block" style="cursor:text;display:block">（圖：<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">小樣本提示</a>與<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">零樣本提示</a>例子，圖片來源：陳華夫重繪自〈<a href="https://arxiv.org/pdf/2206.07682.pdf" target="_blank" class="draft--a">大型語言模型的湧現能力</a>〉（2022），1-30頁）</figcaption></div></figure>
<div class="draft-block draft--p left">本文將基於<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>的文章〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉之上，探討人類<a href="https://zh.wikipedia.org/zh-tw/%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">智慧</a>的本質，及<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>之<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）落後人類有多遠？</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">1）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">的</span><a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a"><span style="font-weight: bold; ">理解</span></a><span style="font-weight: bold; ">能力遠遠落後人類：<br></span>（1）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 的主要優勢在於其對自然語言無與倫比的掌握。它不僅可以生成流暢連貫的文本，還可以通過各種方式<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>和操作文本，例如總結、翻譯或回答極其廣泛的問題。 此外，翻譯不僅指不同自然語言之間的翻譯，還包括語氣和風格上的翻譯，以及跨醫學、法律、會計、計算機編程、音樂等領域的翻譯，清楚地表明<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>可以<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>複雜的想法。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第8頁)<br>（2）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>並非真正的如人類對<a href="https://zh.wikipedia.org/zh-tw/%E6%A6%82%E5%BF%B5" target="_blank" class="draft--a">概念</a>的<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>，很多時候是現場<a href="https://zh.wikipedia.org/zh-tw/%E9%9F%B3%E6%A8%82%E5%8D%B3%E8%88%88" target="_blank" class="draft--a">即興</a>創作。唯一真正的<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>測試是一個人是否可以產生新<a href="https://zh.wikipedia.org/zh-tw/%E7%9F%A5%E8%AF%86" target="_blank" class="draft--a">知識</a>，例如證明新的<a href="https://zh.wikipedia.org/zh-tw/%E6%95%B0%E5%AD%A6%E5%AE%9A%E7%90%86%E5%88%97%E8%A1%A8" target="_blank" class="draft--a">數學定理</a>，而<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>目前無法做到。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9頁)<br>（3）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>比<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>具在<a href="https://en.wikipedia.org/wiki/Common_sense" target="_blank" class="draft--a">常識</a>性的思考有巨大飛躍，<a href="https://en.wikipedia.org/wiki/Common_sense" target="_blank" class="draft--a">常識</a>是對日常事務的合理、實用的判斷，或者是一種基本的<a href="https://en.wikipedia.org/wiki/Perception" target="_blank" class="draft--a">感知</a>、<a href="https://en.wikipedia.org/wiki/Nous" target="_blank" class="draft--a">理解</a>和<a href="https://en.wikipedia.org/wiki/Phronesis" target="_blank" class="draft--a">判斷</a>的能力，其方式幾乎為所有人所共有。針對下面這個測試<a href="https://en.wikipedia.org/wiki/Common_sense" target="_blank" class="draft--a">常識</a>性的思考之經典謎題：<br>「一個獵人向南走一英里，向東走一英里，向北走一英里，最後又回到了起點。 他看到一隻熊並射殺了它。 熊是什麼顏色的？」<br>答案是白色的，因為唯一可能發生這種情況的地方是北極，那裡有北極熊。<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>正確的回答了謎題，而其前身 <a href="https://zh.wikipedia.org/zh-tw/ChatGPT" target="_blank" class="draft--a">ChatGPT</a>（<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>）卻說：「我不知道。」(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第101頁)<br>（4）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>並不理解<a href="https://www.thenewslens.com/article/68371" target="_blank" class="draft--a">音樂的和諧</a>的技能，它生成的<a href="https://zh.wikipedia.org/zh-tw/%E6%97%8B%E5%BE%8B" target="_blank" class="draft--a">旋律</a>中，連續音符幾乎總是彼此相鄰（即C 之後的音符幾乎通常是 B 或 D），並且<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>生成的音樂無法提取出任何清晰的<a href="https://zh.wikipedia.org/zh-tw/%E5%92%8C%E5%BC%A6" target="_blank" class="draft--a">和弦</a>或<a href="https://rickmidi.blogspot.com/2015/03/arpeggios-gmaj7.html" target="_blank" class="draft--a">琶音</a>（即把<a href="https://zh.wikipedia.org/zh-tw/%E5%92%8C%E5%BC%A6" target="_blank" class="draft--a">和弦</a>成音，做排列的彈奏）。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第19頁)<br>（5）所謂<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>（ToM）是將信念、情緒、慾望、意圖和知識等心理狀態歸因於自己和他人，並<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>它們如何影響行為和人們交流的能力。<br>而<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>是否具有<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>呢？<br>經典評估兒童<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>的是「<a href="https://en.wikipedia.org/wiki/Sally%E2%80%93Anne_test" target="_blank" class="draft--a">Sally-Anne</a>測試」：即讓沙莉及安妮共處一室，沙莉首先拿起皮球，放在籃子內，然後離開房間。安妮看到沙莉離開後，偷偷從籃子拿出皮球，再放進一個盒子，並把它蓋起來。然後詢問被測試的小孩湯姆：「沙莉回來後去哪兒找球」？<br>湯姆若回答：「沙莉會去盒子找皮球！」但湯姆答錯了，因為沙莉並不知道安妮已經把皮球移走了。在2010年的一項實驗結果中，6到8歲的兒童答對率是65.5%，而9到14歲兒童答對率是91.9%。（見<a href="https://startupbeat.hkej.com/?p=132282" target="_blank" class="draft--a">GPT-4心智能力如14歲童 通過評估測驗 微軟視AGI雛形</a>）<br>針對類似的<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>測試，<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>和<a href="https://zh.wikipedia.org/zh-tw/ChatGPT" target="_blank" class="draft--a">ChatGPT</a>（<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>）都通過了，而早先的版本<a href="https://www.hdcourse.com/ai/%E6%AF%94%E8%BC%83-chatgpt%E3%80%81text-davinci-003-%E5%8F%8A-openai-api-%E7%9A%84%E5%85%A7%E5%AE%B9%E8%B3%AA%E7%B4%A0/" target="_blank" class="draft--a">text-davinci-003</a> 卻給出錯誤答案。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第54頁)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">2）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">的數學能力很侷限：<br></span>雖然 <a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 在與數學相關的任務中優於其他<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)，如<a href="https://www.softwareadvice.com/bpm/minerva-profile/" target="_blank" class="draft--a"> Minerva</a>，但它仍然不及數學專家，無法進行數學研究。GPT-4 可以回答具有挑戰性的高中數學問題並討論高級數學主題，但它也可能會出錯或提供無意義的回答，(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第30頁)<br><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>基本的局限性是它不能<a href="https://web.ntnu.edu.tw/~algo/Backtracking.html" target="_blank" class="draft--a">回溯</a>（backtrack），所以需要超前<a href="https://en.wikipedia.org/wiki/Plan" target="_blank" class="draft--a">計劃</a>（即帶有時間和資源詳細信息<span style="font-weight: bold; ">的</span>任何<a href="https://en.wikipedia.org/wiki/Diagram" target="_blank" class="draft--a">圖表</a>或步驟列表，用於實現做某事的<a href="https://en.wikipedia.org/wiki/Goal" target="_blank" class="draft--a">目標。</a>它通常被<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>為實現<a href="https://en.wikipedia.org/wiki/Goal" target="_blank" class="draft--a">目標的一</a><a href="https://en.wikipedia.org/wiki/Set_(mathematics)" target="_blank" class="draft--a">組</a><a href="https://en.wikipedia.org/wiki/Modal_logic" target="_blank" class="draft--a">時間性</a>的預期行動。）。這是因為它的輸出是正向產生的，它不能存儲中間結果或進行多步計算。而相對的人類使用<a href="https://en.wikipedia.org/wiki/Scratchpad_memory" target="_blank" class="draft--a">便簽本</a>（scratchpad）來解決問題。<br>GPT-4 的<a href="https://zh.wikipedia.org/zh-tw/%E5%B7%A5%E4%BD%9C%E8%AE%B0%E5%BF%86" target="_blank" class="draft--a">工作記憶</a>也很小，這限制了它解決某些任務的能力。所以很難解決涉及個位數乘法和兩位數加法的基本算術問題，例如，<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>輸出如下：<br>2 * 8 + 7 * 6 = 58<br>7 * 4 + 8 * 8 = 88<br>但答案：”88”是錯的。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第77頁)<br>這些局限性可能來自<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 架構下的<a href="https://www.lesswrong.com/posts/sbaQv8zmRncpmLNKv/the-idea-that-chatgpt-is-simply-predicting-the-next-word-is" target="_blank" class="draft--a">下一個詞預測典範</a>，而它可能缺少“<a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow" target="_blank" class="draft--a">慢思考</a>”部分，無法監督思維過程，及無法使用足夠的<a href="https://zh.wikipedia.org/zh-tw/%E5%B7%A5%E4%BD%9C%E8%AE%B0%E5%BF%86" target="_blank" class="draft--a">工作記憶</a>來解決問題。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第81頁)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">3）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">常犯</span><a href="https://zh.wikipedia.org/zh-tw/%E5%B9%BB%E8%A7%89" target="_blank" class="draft--a"><span style="font-weight: bold; ">幻覺</span></a><span style="font-weight: bold; ">錯誤，要小心並驗證:<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>經常犯數學錯誤或陳述錯誤，這些錯誤很難發現，因為它們可能與正確的信息混在一起。這些錯誤被稱為<a href="https://zh.wikipedia.org/zh-tw/%E5%B9%BB%E8%A7%89" target="_blank" class="draft--a">幻覺</a>，可以是封閉域或開放域。封閉域<a href="https://zh.wikipedia.org/zh-tw/%E5%B9%BB%E8%A7%89" target="_blank" class="draft--a">幻覺</a>發生在特定的環境中，更容易檢測，而開放域幻覺更難發現，需要額外研究。在使用 <a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>寫作時，確保信息真實性可能並不重要，但對於醫學和新聞等領域，仔細檢查所有內容至關重要，用戶必須謹慎並驗證其信息的準確性。同樣重要的是，讀者要小心並驗證<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>生成的信息內容。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.1節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">4）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">被操縱生成虛假信息及發起網絡攻擊:<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>也可能被惡意使用。模型的泛化和交互能力可用於擴大對抗性用途的範圍和強度，從生成虛假信息到對計算基礎設施發起網絡攻擊。這些模型可以通過情境化和個性化互動來顯著地操縱、說服或影響人們，以最大限度地影響他們幾代人。借助<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>自動化，可以啟用旨在構建虛假信息計劃的新用途，這些計劃可以生成和組合多個內容以在短期和長期範圍內進行說服。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.2節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">5）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">對某些行為具有</span><a href="https://zh.wikipedia.org/wiki/%E6%AD%A7%E8%A6%96" target="_blank" class="draft--a"><span style="font-weight: bold; ">歧視</span></a><span style="font-weight: bold; ">的</span><a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a"><span style="font-weight: bold; ">偏見</span></a><span style="font-weight: bold; ">：<br></span><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)是使用來自互聯網的數據和精選的人工指令進行訓練的。然而，這些數據集是有<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>（指人們基於成員身份，而對一個人或成員的情感或態度<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B#cite_note-1" target="_blank" class="draft--a">[1]</a>。因這個態度而衍生的行為是<a href="https://zh.wikipedia.org/wiki/%E6%AD%A7%E8%A6%96" target="_blank" class="draft--a">歧視</a>，而人們如何描述一個群組內所有成員的特徵稱為<a href="https://zh.wikipedia.org/wiki/%E5%88%BB%E6%9D%BF%E5%8D%B0%E8%B1%A1" target="_blank" class="draft--a">刻板印象</a>）。先前的研究表明，當<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)用於生成內容或做出決策時，它們會放大現有的<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>。雖然<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>與早期<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)不同，但我們也要迫切的了解 <a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>是否存在<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>以及如何存在<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>，以及如何使用其功能來減少<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.3節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">6）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">引發了教育和失業的問題：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 是一台可以做很多事情的機器，即使在醫學和法律等領域也是如此。這可能會引起人們擔心它會如何影響需要大量培訓的職業。有些人可能擔心人工智能系統會取代或降低人類工人的地位，引發了教育和失業的問題。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.4節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">7）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">加劇</span><a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a"><span style="font-weight: bold; ">人工智慧</span></a><span style="font-weight: bold; ">（AI）使用的不平等及個人隱私洩露風險：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的使用需要收費，將加劇<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>（AI）使用的不平等。因為個人、組織和國家可能無法負擔使用<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的費用，<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>實質上只對有特權的人開放，而擴大了社會使用<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>（AI）的鴻溝和不平等。<br>並且由於<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>由強大的推理能力，在其與人們的聊天中捕獲了人們的隱私，於是加遽了個人隱私洩露風險。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.5節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">8）</span><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"><span style="font-weight: bold; ">大型語言模型</span></a><span style="font-weight: bold; ">(</span><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"><span style="font-weight: bold; "> LLM </span></a><span style="font-weight: bold; ">)的研發耗費鉅資，恐被資本雄厚的公司壟斷：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>是一種<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)，建立在<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）神經網絡：</div>
<figure class="draft--imgNormal draft-block"><div><img data-src="https://images.vocus.cc/c6ab0518-05a8-4b52-ae69-8353f9fd19ac.jpg" data-width="1551" data-height="1186" data-position="center" src="https://images.vocus.cc/c6ab0518-05a8-4b52-ae69-8353f9fd19ac.jpg" referrerpolicy="no-referrer"><figcaption class="imageCaption draft-block" style="cursor:text;display:block">（圖：<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）架構，圖片來源：<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）─維基百科）</figcaption></div></figure>
<div class="draft-block draft--p left"><a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">轉換器（Transformer）</a>與<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">循環神經網絡</a>(<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>) 都是處<a href="https://baike.baidu.com/item/%E9%A1%BA%E5%BA%8F%E8%BE%93%E5%85%A5%2F%E8%BE%93%E5%87%BA/22083230" target="_blank" class="draft--a">理順序輸入</a>數據，但與<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>不同，<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>一次處理所有輸入，並取代了<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>的<a href="https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank" class="draft--a">長短期記憶</a>(LSTM)。其<a href="https://medium.com/@x02018991/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98-self-attention-fa6897080a0a" target="_blank" class="draft--a">自注意</a>的機制為輸入序列中的任何位置提供上下文信息。輸入文本通過<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記解析器</a>為<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token），再通過「詞嵌入」(<a href="https://en.wikipedia.org/wiki/Word_embedding" target="_blank" class="draft--a">word embedding</a>)轉換為向量。然後將<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>的位置信息添加到「詞嵌入」中，如果輸入數據是自然語言句子，則<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>不必一次處理一個詞。與 <a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>相比，這允許更多的<a href="https://en.wikipedia.org/wiki/Parallel_computing" target="_blank" class="draft--a">並行化</a>，因此減少了訓練時間。</div>
<div class="draft-block draft--p left"><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>) 之<a href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1" target="_blank" class="draft--a">神經網路</a>的參數數量隨時間呈指數級增長：</div>
<figure class="draft--imgNormal draft-block"><div><img data-src="https://images.vocus.cc/c47ad2a3-a27f-46d6-a20e-59698f73eb22.jpg" data-width="1520" data-height="1145" data-position="center" src="https://images.vocus.cc/c47ad2a3-a27f-46d6-a20e-59698f73eb22.jpg" referrerpolicy="no-referrer"><figcaption class="imageCaption draft-block" style="cursor:text;display:block">（圖：<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的參數數量隨時間呈指數級增長，圖形來源：<a href="https://www.microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/" target="_blank" class="draft--a">使用DeepSpeed和Megatron訓練全球最大最強大的生成語言模型Megatron-Turing NLG 530B</a>）</figcaption></div></figure>
<div class="draft-block draft--p left">訓練如此大型模型不僅耗時，也耗鉅資；例如，訓練<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>這樣的<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)：82 G參數及150G<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token），一般使用1,024 個 <a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a>，其訓練所耗費的時間T（天）估計如下：<br><span style="font-weight: bold; ">T</span> <span style="font-style: italic; ">≈</span> (6 x <span style="font-weight: bold; ">N</span> x <span style="font-weight: bold; ">D</span>) / （1024 x <span style="font-weight: bold; ">𝜏</span> ）<br><span style="font-weight: bold; ">𝜏：</span>是<a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a>之<a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet.pdf" target="_blank" class="draft--a">float16 FLOPs 吞吐量</a><br>      = 312 teraFLOPS = 312兆FLOPS = 3.12 x 10exp14 FLOPS<br>      （按FLOPS = 每秒的浮點運算數）<br><span style="font-weight: bold; ">N:</span> 模型的參數之數目 = 8.2 x 10exp10 = 82 G參數 = 82 B參數<br><span style="font-weight: bold; ">D:</span> 模型的<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token）數目 = 1.5 x 10exp11 = 150 B<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a><br>計算結果：<br><span style="font-weight: bold; ">T </span>= (6 x 8.2 x 1010 x 1.5 x 1011) / （1024 x 3.12 x 1014 ）/（8.64 x 104秒/天 ）= 2.67 天。<br>此結果與比<a href="https://arxiv.org/abs/2109.04650" target="_blank" class="draft--a">白皮書</a>的培訓耗時13.4 天小了約 5 倍，卻是在正確的數量級。（見<a href="https://medium.com/@dzmitrybahdanau/the-flops-calculus-of-language-model-training-3b19c1f025e4" target="_blank" class="draft--a">語言模型訓練的FLOPs微積分</a>）<br>（按：單位的中英對譯:<br>billion  B   x10exp9     （美國，法國）十億，（英國，德國）萬億<br>giga     G   x 10exp9    十億 (<a href="https://zh.wikipedia.org/wiki/%E5%9B%BD%E9%99%85%E5%8D%95%E4%BD%8D%E5%88%B6%E8%AF%8D%E5%A4%B4" target="_blank" class="draft--a">國際單位制詞頭</a>)<br>tera      T   x 10exp12  兆<br>peta     P   x 10exp15  拍(千兆)<br>exa       E   x 10exp18  艾(百萬兆) 百京<br>zetta    Z   x 10exp21  十垓<br>yotta    Y   x 10exp24  一秭）</div>
<div class="draft-block draft--p left">而一個<a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a> 晶片價值10,000 美元。（見<a href="https://www.cnbc.com/2023/02/23/nvidias-a100-is-the-10000-chip-powering-the-race-for-ai-.html" target="_blank" class="draft--a">認識價值 10,000 美元的 Nvidia 芯片，為 AI 競賽提供動力</a>）最新的<a href="https://www.nvidia.com/zh-tw/data-center/h100/" target="_blank" class="draft--a">NVIDIA H100</a> 若結合的技術創新，可加速<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)速度，比前一代的<a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a>快上30倍，但一個<a href="https://www.nvidia.com/zh-tw/data-center/h100/" target="_blank" class="draft--a">NVIDIA H100</a>價格超過40,000美元。(見<a href="https://www.cnbc.com/2023/04/14/nvidias-h100-ai-chips-selling-for-more-than-40000-on-ebay.html" target="_blank" class="draft--a">科技Nvidia 的頂級 AI 芯片在 eBay 上的售價超過 40,000 美元</a>)<br>通常，<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的研發、訓練、商轉可透過付費的<a href="https://zh.wikipedia.org/zh-tw/%E9%9B%B2%E7%AB%AF%E9%81%8B%E7%AE%97" target="_blank" class="draft--a">雲端計算</a>。（見<a href="https://venturebeat.com/ai/nvidia-enables-broader-usage-of-ai-with-llm-cloud-services/" target="_blank" class="draft--a">Nvidia 通過 LLM 雲服務實現 AI 的更廣泛使用</a>）所以付費的<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>的使用是發展<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的關鍵。<br>2020年，美國<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>約141 x 10exp18FLOPS，居全球第二。而中國<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>達到135 x 10exp18FLOPS，居全球第二。 (見<a href="https://www.diskmfr.com/this-article-is-worth-reading-about-the-computing-power/" target="_blank" class="draft--a">這篇關於“算力”的文章值得一讀</a>)<br>中國2020/9月成立<a href="https://zh.wikipedia.org/zh-tw/%E4%B8%9C%E6%95%B0%E8%A5%BF%E7%AE%97" target="_blank" class="draft--a">東數西算</a>產業聯盟，將<a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%9C%8B%E6%9D%B1%E9%83%A8" target="_blank" class="draft--a">中國東部</a>各行業產生的<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE" target="_blank" class="draft--a">數據</a>通過<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C" target="_blank" class="draft--a">網絡</a>送往位於<a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%9C%8B%E8%A5%BF%E9%83%A8" target="_blank" class="draft--a">中國西部</a>地區的<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83" target="_blank" class="draft--a">數據中心</a>處理、計算和存儲。據估計，2023年中國<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>總規模達到180 x 10exp18FLOPS，存力（儲存能力）總規模超過1000 x 10exp15 B（1兆GB）= 1 x 10exp18 B。國家樞紐節點間的網路<a href="https://www.eettaiwan.com/20180710nt31-what-needs-happen-5g-be-reality/" target="_blank" class="draft--a">單向延遲</a>為20毫秒以內，<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>核心產業規模達到1.8兆人民幣。（見<a href="https://www.chinatimes.com/newspapers/20230412000671-260303?chdtv" target="_blank" class="draft--a">大陸算力產業年增近3成 規模僅次美國</a>）<br>從上面的分析可見，資本雄厚的公司如<a href="https://zh.wikipedia.org/zh-tw/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E9%9B%86%E5%9B%A2" target="_blank" class="draft--a">阿里巴巴</a>、<a href="https://www.baidu.com/" target="_blank" class="draft--a">百度</a>、<a href="https://zh.wikipedia.org/zh-tw/%E8%85%BE%E8%AE%AF" target="_blank" class="draft--a">騰訊</a>、<a href="https://www.google.com/?hl=zh_tw" target="_blank" class="draft--a">谷歌</a>、<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>、<a href="https://www.nvidia.com/zh-tw/data-center/h100/" target="_blank" class="draft--a">輝達</a>將壟斷<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的研發、訓練、商轉。</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">9）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">的思考能力遠遠落後人類，</span><a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a"><span style="font-weight: bold; ">人工通用智能</span></a><span style="font-weight: bold; ">（</span><a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a"><span style="font-weight: bold; ">AGI</span></a><span style="font-weight: bold; ">）的研發將是耗費鉅資的美夢：<br></span>寫〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉的<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>工程師團隊們坦白的承認，他們並不瞭解，為何<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>只具有簡單的<a href="https://zh.wikipedia.org/zh-tw/%E7%AE%97%E6%B3%95" target="_blank" class="draft--a">演算法</a>（如梯度下降）配合大量參數與<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>的<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>，卻能有通用和靈活的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）？<br>有些專家認為是來自<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>能力（當一個實體被觀察到具有其各部分自身不具有的屬性或行為時，就會出現<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>，這些屬性或行為只有因為各個部分之相互作用時才會出現<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>能力）。如果一種能力不存在於較小的模型中但存在於較大的模型中，即是<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>的。（見〈<a href="https://arxiv.org/pdf/2206.07682.pdf" target="_blank" class="draft--a">大型語言模型的湧現能力</a>〉（2022，1─30頁）<br>但<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>工程師團隊們打臉<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>能力，他們認為；「儘管人們對 LLM 的能力問題非常感興趣，但迄今為止的進展非常有限，只有玩具模型證明了一些<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>現象。」(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第95頁)<br>相對於<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>神經網絡所展現<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>，人類<a href="https://cogns.northwestern.edu/cbmg/Wedeen2012.pdf" target="_blank" class="draft--a">腦神經記憶網絡</a>所展現的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>是對<a href="https://zh.wikipedia.org/zh-tw/%E6%A6%82%E5%BF%B5" target="_blank" class="draft--a">概念</a>的<a href="https://zh.wikipedia.org/wiki/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>，而在大腦中建立外部<a href="https://zh.wikipedia.org/zh-tw/%E7%8F%BE%E5%AF%A6" target="_blank" class="draft--a">現實</a>的<a href="https://zh.wikipedia.org/zh-tw/%E6%A8%A1%E5%9E%8B" target="_blank" class="draft--a">模型</a>。（詳細，請看拙文<a href="https://vocus.cc/article/604c3f83fd89780001077ff0" target="_blank" class="draft--a">什麼是「思考」？如何「洞識」？何謂「思想家」？─學習的本質（2）</a>）<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>恐怕遠用無法追趕上人類的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>，那麼，<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的研發將是耗費鉅資的美夢。</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">結論：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>具有推理、創造力和演繹等核心心智能力，顯示出了<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）火花，但<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>神經網絡所展現的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>遠遠落後人類<a href="https://cogns.northwestern.edu/cbmg/Wedeen2012.pdf" target="_blank" class="draft--a">腦神經記憶網絡</a>的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>，<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的研發將是耗費鉅資的美夢。</div>
<div class="draft-block draft--p left">請看「陳華夫專欄」─學習的本質─系列文章：<br> （<br> <a href="https://vocus.cc/article/63d49419fd897800010cd235" target="_blank" class="draft--a">思考、記憶、人腦解決之「強化學習式」思考架構─學習的本質（1）</a><br> <a href="https://vocus.cc/article/604c3f83fd89780001077ff0" target="_blank" class="draft--a">什麼是「思考」？如何「洞識」？何謂「思想家」？─學習的本質（2）</a><br> <a href="https://vocus.cc/article/6038be87fd8978000117506f" target="_blank" class="draft--a">什麼是「記憶」？如何「記憶」？「記憶」的本質？─學習的本質（3）</a><br> <a href="https://vocus.cc/article/6321b683fd897800012008af" target="_blank" class="draft--a">學習的真相與反思─學習的本質（4）</a><br> <a href="https://vocus.cc/article/5e7fde9dfd89780001a56547" target="_blank" class="draft--a">「施捨」就是人生的「現代開悟」─學習的本質（5）</a><br> <a href="https://vocus.cc/article/5e5f38b0fd8978000185e19d" target="_blank" class="draft--a">談「恐懼」─學習的本質（6）</a><br> <a href="https://vocus.cc/article/5e60d938fd89780001881b3c" target="_blank" class="draft--a">探究華人的「罪惡感」？─學習的本質（7）</a><br> <a href="https://vocus.cc/article/5f229064fd89780001424196" target="_blank" class="draft--a">你孤獨了嗎？─學習的本質（8）</a><br> <a href="https://vocus.cc/article/6114a838fd89780001508544" target="_blank" class="draft--a">人腦如何創新思考？─學習的本質（9）</a><br> <a href="https://vocus.cc/article/61163d1dfd897800013867bc" target="_blank" class="draft--a">「現代開悟」的本質及釋義─學習的本質（10）</a><br> <a href="https://vocus.cc/article/5e670b87fd8978000159a6c6" target="_blank" class="draft--a">你「現代開悟」了嗎？─學習的本質（11）</a><a href="https://vocus.cc/article/6208abf0fd89780001534350" target="_blank" class="draft--a"><br> 人工智慧的「強化學習」與人類學習的優劣─學習的本質（12）</a><a href="https://vocus.cc/article/6208abf0fd89780001534350" target="_blank" class="draft--a"><br> </a><a href="https://vocus.cc/article/6250d34dfd897800016f85ef" target="_blank" class="draft--a">伽馬波（40赫茲）、記憶、失智症、及音樂治療─學習的本質（13）<br> </a><a href="https://vocus.cc/article/6198a8eefd8978000162c3fc" target="_blank" class="draft--a">省思物理科學教育的真相─學習的本質（14）<br> </a><a href="https://vocus.cc/article/618f75fbfd8978000117f4d9" target="_blank" class="draft--a">人類智慧真正優於AI人工智慧之處為何？─學習的本質（15）<br> </a><a href="https://vocus.cc/article/610f9ef4fd8978000143769d" target="_blank" class="draft--a">細述我親歷40年的學習之旅─學習的本質（16）</a><br> <a href="https://vocus.cc/editor/63df1b61fd897800013f333f" target="_blank" class="draft--a">AI幫助人們改善記憶、思考能力─適用於年輕與銀髮人─學習的本質（17）</a><br> <a href="https://vocus.cc/article/63e9f66afd8978000157c9ba" target="_blank" class="draft--a">AI徹底改變大學理工教育的面貌─學習的本質（18）</a><br> <a href="https://vocus.cc/article/63f09baffd897800019abe30" target="_blank" class="draft--a">AI模擬人類學習真能比人類更創新嗎？─學習的本質（19）</a><br> <a href="https://vocus.cc/article/63fd7f8afd89780001fa2556" target="_blank" class="draft--a">AI深度學習與《易經》的學習真有差異嗎？─學習的本質（20）</a><br> <a href="https://vocus.cc/article/6402b719fd89780001dc435d" target="_blank" class="draft--a">AI之ChatGPT的繪畫審美能力賞析─學習的本質（21）</a><br> <a href="https://vocus.cc/article/643b3a81fd89780001778127" target="_blank" class="draft--a">請看懂智慧的本質：GTP4的「人工通用智能」（AGI）落後人類有多遠？─學習的本質（22）</a><br> ）</div>
