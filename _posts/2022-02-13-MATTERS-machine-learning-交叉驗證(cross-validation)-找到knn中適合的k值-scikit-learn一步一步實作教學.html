---
layout: post
title: Machine Learning-交叉驗證(Cross Validation)-找到KNN中適合的K值-Scikit Learn一步一步實作教學
date: 2022-02-13 15:08:50.000000000 +00:00
link: https://matters.news/@CHWang/machine-learning-%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89-cross-validation-%E6%89%BE%E5%88%B0knn%E4%B8%AD%E9%81%A9%E5%90%88%E7%9A%84k%E5%80%BC-scikit-learn%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E5%AF%A6%E4%BD%9C%E6%95%99%E5%AD%B8-bafyreic7j2nu52zfm6dsry5qkmustxqqdbvx3hqqz7vwwdwkophimdju6y
categories: matters
tags: blog
author: 為自己Coding
---

<h3><br></h3><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">Github完整程式碼</a></p><figure class="image"><img src="https://assets.matters.news/embed/4e18c6ff-bc39-4365-95cc-9923473f4b03.jpeg" data-asset-id="4e18c6ff-bc39-4365-95cc-9923473f4b03" referrerpolicy="no-referrer"><figcaption><span>攝影師：Julius Silver，連結：Pexels</span></figcaption></figure><h4><br></h4><h4><br></h4><h2><strong>1. 交叉驗證(Cross validation)是什麼?</strong></h2><p><br></p><p>簡單來說就是將整個數據集(Dataset)切成許多集(組)，一部份的組作為訓練集，另一部分做為測試集，達到訓練與評價模型的效果</p><h4><br></h4><h4><br></h4><h2><strong>2. 為什麼需要交叉驗證?</strong></h2><p><br></p><p>a. 如果我們只用一組的訓練集來訓練模型，會導致我們的結果可能會有偏差，也就是換了訓練集資料後，訓練出來的模型預測能力可能不同，但都是源自同一個資料集來創建模型，更有效的方法是，將不同的資料組輪流成為訓練集，然後平均得出來的結果，就能更客觀的了解模型的預測能力</p><p>b. 我們的數據集不夠大量，有限的資源下要獲得更多的資訊 </p><p>c. 可以找到合適的模型或參數，像是找到KNN中符合資料的K值，讓機器學習模型表現最好</p><h3><br></h3><h3><br></h3><h2><strong>3. 交叉驗證的方法?</strong></h2><p><br></p><blockquote>a.留出法 (holdout cross validation)</blockquote><blockquote>b. k折交叉驗證法 (k-fold Cross Validation)</blockquote><blockquote>c.留一法 (Leave one out cross validation) </blockquote><blockquote>d. Bootstrap Sampling</blockquote><h4><br></h4><h4><br></h4><h2><strong>4. 留出法 (holdout cross validation)</strong></h2><p><br></p><figure class="image"><img src="https://assets.matters.news/embed/cce6bc29-5b8e-491d-ada2-998cb4aeefe3.png" data-asset-id="cce6bc29-5b8e-491d-ada2-998cb4aeefe3" referrerpolicy="no-referrer"><figcaption><span></span></figcaption></figure><p><br></p><p>a. 說明: 最簡單的交叉驗證方法，直接將原始數據隨機切成三等份，訓練集、驗證集和測試集</p><p>b. 缺點: </p><p>i.如果只做一次劃分，切割三份的比例，與切割後的分布是否與原數據相同等因素很難拿捏</p><p>ii. 不同的劃分方式，會導致不同的最佳模型</p><h4>iii. 用來訓練模型的數據(訓練集)更少了</h4><h4><br></h4><h2><strong>5. k折交叉驗證法 (k-fold Cross Validation)</strong></h2><p><br></p><figure class="image"><img src="https://assets.matters.news/embed/50cfed0d-26d4-485b-8dfd-4268567ed21e.png" data-asset-id="50cfed0d-26d4-485b-8dfd-4268567ed21e" referrerpolicy="no-referrer"><figcaption><span></span></figcaption></figure><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">a. 說明: 改進了留出法對數據劃分可能存在的缺點，首先將數據集切割成k組，然後輪流在k組中挑選一組作為測試集，其它都為訓練集，然後執行測試，進行了k次後，將每次的測試結果平均起來，就為在執行k折交叉驗證法 (k-fold Cross Validation)下模型的性能指標</a></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">b. k取值: 通常都取10，資料量大時，建議設小，反之設大，這樣在資料數量小的時候能多分一點數據給訓練集來訓練模型</a></p><h4><strong>6. 留一法 (Leave one out cross validation)  </strong></h4><figure class="image"><img src="https://assets.matters.news/embed/9acdcd62-8177-4350-a6f9-a9550865748f.png" data-asset-id="9acdcd62-8177-4350-a6f9-a9550865748f" referrerpolicy="no-referrer"><figcaption><span></span></figcaption></figure><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">a. 說明: 很像k折交叉驗證法，但把k值設為樣本數量T，然後每次測試集只有一個樣本，其餘樣本的是訓練集，進行T次的訓練與預測後，得到評價模型結果</a></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">b. 使用時機: 數據量真的很少的時候</a></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">c. 缺點: 數據量大的話，需要大量的運算</a></p><h4><strong>7. 自助抽樣法 (Bootstrap Sampling) </strong></h4><figure class="image"><img src="https://assets.matters.news/embed/a3d93ec7-65e2-4146-8d3f-2850080ad814.png" data-asset-id="a3d93ec7-65e2-4146-8d3f-2850080ad814" referrerpolicy="no-referrer"><figcaption><span></span></figcaption></figure><p><br></p><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">a. 說明: 在有N個數據資料中，進行N次的隨機抽出組成一個新的數據集，由於時隨機所以可能有資料被重複抽出，有的完全沒有被選中，這時組成的新數據集即為訓練集，有大概36.8%的數據不會被選中，沒有被抽中的數據為驗證集</a></p><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">b. 使用時機: 除非數據量真的非常少，不然通常不會被使用</a></p><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">c. 優點: 會有36.8%的數據不會被選成訓練集，對於資料量小的的數據集，不用切成更小的測試集，也就不會影響模型的預測能力</a></p><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">d. 缺點: 訓練集的分布與原始數據一定不同，需要引入估計偏差的方法</a></p><h4><strong>8. 如何利用交叉驗證(Cross Validation)來找尋最佳KNN中的K值?</strong></h4><h4><strong>實作</strong></h4><p>在Machine Learning-KNN演算法- Python實作-Scikit Learn一步一步實作教學 這篇文章中我們一起學習了如何實作KNN，這邊我就不對KNN的套件多做介紹，直接使用喔</p><p><strong>a. 導入交叉驗證(Cross Validation)的套件</strong></p><pre class="ql-syntax">from sklearn.model_selection import cross_val_score
</pre><p><strong>b. 導入KNN的套件 與 數據處理所需的套件</strong></p><pre class="ql-syntax">## 導入Python 數據處理套件 numpy and pandas
import numpy as np
import pandas as pd
## 導入sklearn(Scikit Learn)
## 導入sklearn的數據集
from sklearn import datasets
## 導入分割train data 與 test data的套件
from sklearn.model_selection import train_test_split
## 導入KNN 模型
from sklearn.neighbors import KNeighborsClassifier
</pre><p><strong>c. 導入Iris Data 當我們這次實作的數據庫</strong></p><pre class="ql-syntax">iris_flower = datasets.load_iris()
X = iris_flower.data
y = iris_flower.target
</pre><p><strong>d. 建立KNN模型</strong></p><pre class="ql-syntax">##建立 KNN Model
## KNN Classifier 參數設定
knn_model = KNeighborsClassifier(n_neighbors = 10, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=1)
</pre><p><strong>e. 交叉驗證(Cross Validation)法實作</strong></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">i. cv: 將資料分成幾組，如上面我們提到的k折交叉驗證法 (k-fold Cross Validation)來實作交叉驗證(Cross Validation)的功能</a></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">ii. scoring: 得分方式 ，accuracy: 為一種方法，用以顯示準確度得值(越高越準確)</a></p><p><strong>小筆記: scoring除了有’accuracy’，也有計算平均方差的'mean_squared_error', 這個方法通常是用在評斷回歸模型的好壞</strong></p><pre class="ql-syntax">accuracy = cross_val_score(knn_model, X, y, cv=10, scoring=”accuracy”)
print(accuracy)
print(accuracy.mean()*100,’%’)
</pre><p> iii. 執行結果</p><figure class="image"><img src="https://assets.matters.news/embed/cb9eac2a-a5b8-45a5-b873-d59e4cb9d19d.png" data-asset-id="cb9eac2a-a5b8-45a5-b873-d59e4cb9d19d" referrerpolicy="no-referrer"><figcaption><span></span></figcaption></figure><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">vi. 可以從accuracy串列中，看到有些組是100%，有些組則是大概93%，也就是說如果我們剛好取的是第一組，就會誤以為模型準確度(Accuracy)一定是100%，但實際上只是剛好取到這樣的資料組合</a></p><h4><strong>f. 最佳K值</strong></h4><p><br></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank"> </a></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">i. 找到最佳K值，也就是KNN模型參數裡面的n_neighbors值</a></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">ii. 我這邊想設定我查找的k值範圍落在3~33，也就是說我想知道當K值等於3~33的時候，模型表現的狀況，來決定我的最佳K值</a></p><pre class="ql-syntax">## 設定欲找尋的k值範圍
k_value_range = range(3,34)
## 裝測試結果的平均分數
k_value_scores = []
for k in k_value_range:
 knn_model = KNeighborsClassifier(n_neighbors = k, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=1)
 accuracy = cross_val_score(knn_model, X, y, cv=10, scoring=”accuracy”)
 print(“K值: “, k)
 print(“Accuracy: “, accuracy.mean())
 k_value_scores.append(accuracy.mean())
print(k_value_scores)
## 找一個最佳的k值，由於k的初始值我們設在3，所以要加三
print("最佳K值: " ,k_value_scores.index(max(k_value_scores))+3)
</pre><p><br></p><p><strong>g. 資料視覺化</strong></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">i. fontproperties=”SimSun”: 宋體，解決中文顯示問題</a></p><pre class="ql-syntax">## Data Visualization
import matplotlib.pyplot as plt
 
plt.plot(k_value_range,k_value_scores, marker = ‘o’)
plt.title(“找尋最佳KNN裡的K值”, fontproperties=”SimSun”)
plt.xlabel(‘K 值’, fontproperties=”SimSun”)
plt.ylabel(‘Accuracy’)
plt.show()
</pre><p><strong>h. 完整程式碼</strong></p><pre class="ql-syntax">## 導入交叉驗證(Cross Validation)的套件
from sklearn.model_selection import cross_val_score
## 導入Python 數據處理套件 numpy and pandas
import numpy as np
import pandas as pd
## 導入sklearn(Scikit Learn)
## 導入sklearn的數據集
from sklearn import datasets
## 導入分割train data 與 test data的套件
from sklearn.model_selection import train_test_split
## 導入KNN 模型
from sklearn.neighbors import KNeighborsClassifier
## 導入Iris Data 當我們這次實作的數據庫
iris_flower = datasets.load_iris()
X = iris_flower.data
y = iris_flower.target
##建立 KNN Model
## KNN Classifier 參數設定
knn_model = KNeighborsClassifier(n_neighbors = 10, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=1)
## 交叉驗證(Cross Validation)法實作
accuracy = cross_val_score(knn_model, X, y, cv=10, scoring=”accuracy”)
print(accuracy)
print(accuracy.mean()*100,’%’)
## 找最佳K值
## 設定欲找尋的k值範圍
k_value_range = range(3,34)
## 裝測試結果的平均分數
k_value_scores = []
for k in k_value_range:
 knn_model = KNeighborsClassifier(n_neighbors = k, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)
 accuracy = cross_val_score(knn_model, X, y, cv=10, scoring="accuracy")
 print("K值: "+ str(k) +" Accuracy: "+ str(accuracy.mean()))
 k_value_scores.append(accuracy.mean())
print(k_value_scores)
## 找一個最佳的k值，由於k的初始值我們設在3，所以要加三
print("最佳K值: " ,k_value_scores.index(max(k_value_scores))+3)
## Data Visualization
import matplotlib.pyplot as plt
 
plt.plot(k_value_range,k_value_scores, marker = ‘o’)
plt.title(“找尋最佳KNN裡的K值”, fontproperties=”SimSun”)
plt.xlabel(‘K 值’, fontproperties=”SimSun”)
plt.ylabel(‘Accuracy’)
plt.show()
</pre><p><strong>i. 執行結果</strong></p><pre class="ql-syntax">[1.    0.93333333 1.    1.    1.    0.86666667
 0.93333333 0.93333333 1.    1.   ]
96.66666666666669 %
K值: 3 Accuracy: 0.9666666666666666
K值: 4 Accuracy: 0.9666666666666666
K值: 5 Accuracy: 0.9666666666666668
K值: 6 Accuracy: 0.9666666666666668
K值: 7 Accuracy: 0.9666666666666668
K值: 8 Accuracy: 0.9666666666666668
K值: 9 Accuracy: 0.9733333333333334
K值: 10 Accuracy: 0.9666666666666668
K值: 11 Accuracy: 0.9666666666666668
K值: 12 Accuracy: 0.9733333333333334
K值: 13 Accuracy: 0.9800000000000001
K值: 14 Accuracy: 0.9733333333333334
K值: 15 Accuracy: 0.9733333333333334
K值: 16 Accuracy: 0.9733333333333334
K值: 17 Accuracy: 0.9733333333333334
K值: 18 Accuracy: 0.9800000000000001
K值: 19 Accuracy: 0.9733333333333334
K值: 20 Accuracy: 0.9800000000000001
K值: 21 Accuracy: 0.9666666666666666
K值: 22 Accuracy: 0.9666666666666666
K值: 23 Accuracy: 0.9733333333333334
K值: 24 Accuracy: 0.96
K值: 25 Accuracy: 0.9666666666666666
K值: 26 Accuracy: 0.96
K值: 27 Accuracy: 0.9666666666666666
K值: 28 Accuracy: 0.9533333333333334
K值: 29 Accuracy: 0.9533333333333334
K值: 30 Accuracy: 0.9533333333333334
K值: 31 Accuracy: 0.9466666666666667
K值: 32 Accuracy: 0.9466666666666667
K值: 33 Accuracy: 0.9466666666666667
</pre><figure class="image"><img src="https://assets.matters.news/embed/71310dc3-3eaa-48a8-93e5-ac66ab129a5f.png" data-asset-id="71310dc3-3eaa-48a8-93e5-ac66ab129a5f" referrerpolicy="no-referrer"><figcaption><span></span></figcaption></figure><p><br></p><p><strong>可以從印出的數據與圖中找到在我們設定的範圍中(3~33)最佳的K值為13、18跟20，他們的Accuracy為0.9800000000000001，數據圖中可以清楚看到有三個點有最高的準確度(Accuracy)，所以就取它們之一當K值囉</strong></p><p><br></p><p><br></p><blockquote>這樣我們就可以驗證我們的模型囉!! 也可以找到最佳的K值(參數)，來幫助我們建立最佳的預測模型!! 希望有幫助到大家，可以開始驗證起來</blockquote><h2><br></h2><h2><br></h2><h2><strong>Reference</strong></h2><p><a href="https://randomforests.wordpress.com/2014/02/02/basics-of-k-fold-cross-validation-and-gridsearchcv-in-scikit-learn/" target="_blank"><strong>K-Fold Cross Validation and GridSearchCV in Scikit-Learn</strong></a></p><p><a href="https://randomforests.wordpress.com/2014/02/02/basics-of-k-fold-cross-validation-and-gridsearchcv-in-scikit-learn/" target="_blank"><em>Python is one of the most popular open-source languages for data analysis (along with R), and for good reason. With…</em>randomforests.wordpress.com</a></p><p><a href="https://github.com/chwang12341/Machine-Learning/tree/master/Cross-Validation" target="_blank">[</a><strong>[Day29]機器學習：交叉驗證！ - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天</strong></p><p><em>倒數第二天！ 今天要來看機器學習中很重要的 交叉驗證(Cross validation) ： 一般來說我們會將數據分為兩個部分，一部分用來訓練，一部分用來測試，交叉驗證是一種統計學上將樣本切割成多個小子集的做測試與訓練。…</em>ithelp.ithome.com.tw](<a href="https://ithelp.ithome.com.tw/articles/10197461" target="_blank">https://ithelp.ithome.com.tw/articles/10197461</a>)</p><p><br></p><p><a href="https://kknews.cc/code/994o5g5.html" target="_blank">https://kknews.cc/code/994o5g5.html</a></p>
