---
layout: post
title: 請看懂智慧的本質：GPT-4的「人工通用智能」（AGI）落後人類有多遠？─學習的本質（22）
date: 2023-04-16 00:00:01.000000000 +00:00
link: https://vocus.cc/article/643b3a81fd89780001778127
categories: vocus
tags: blog
author: 陳華夫hwafuchen
---

<div class="draft-block draft--p left">（本文最近一次更新在2024/6/2）</div>
<div class="draft-block draft--p left">作者：陳華夫</div>
<div class="draft-block draft--p left"><a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>（AI）近年進步神速，2017年<a href="https://www.google.com.tw/" target="_blank" class="draft--a">谷歌</a>（Google）的<a href="https://zh.wikipedia.org/wiki/DeepMind" target="_blank" class="draft--a">DeepMind</a>公司推出超級電腦圍棋 <a href="https://zh.wikipedia.org/wiki/AlphaGo_Zero" target="_blank" class="draft--a">AlphaGo Zero</a>，棋力遠遠超過人類。2022年<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>公司推出<a href="https://zh.wikipedia.org/zh-tw/ChatGPT" target="_blank" class="draft--a">ChatGPT</a>聊天機器人（<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>版本），它的<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）<a href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1" target="_blank" class="draft--a">神經網路</a>包含175G參數，800GB<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token），其訓練數據庫基本上是數十萬篇英文學術論文、新聞報導、書籍和社群媒體貼文。它雖然沒有人類<a href="https://zh.wikipedia.org/zh-tw/%E6%84%8F%E8%AF%86" target="_blank" class="draft--a">意識</a>的<a href="https://en.wikipedia.org/wiki/Teleonomy" target="_blank" class="draft--a">目的性</a>，但它擁有接近人類水平的<a href="https://zh.wikipedia.org/zh-tw/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86" target="_blank" class="draft--a">自然語言處理</a>（NLP）能力及對話<a href="https://zh.wikipedia.org/zh-tw/%E9%80%BB%E8%BE%91" target="_blank" class="draft--a">邏輯</a>。</div>
<div class="draft-block draft--p left">最近<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>執行長山姆·奧特曼被董事會開除，但一週內又回歸，而這場公司內鬥的遠因是：「<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a> 最初是一家非營利組織，希望創造出一種能真正改變人類的通用人工智慧，但要訓練模型，它需要大量資金和大量數據。因此，它成立了一家營利子公司，並引入了微軟的力量和資源。」而內鬥的相互衝突是：「因為社會上存在著兩種相互衝突的觀點。 一部分的人認為人工智慧是一種非常強大的工具，但同時也對社會造成了危險，因此主張放慢這項工具的發展速度。另一方面，也有人認為 <a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a> 將可能成為史上最大的科技公司，並為公司賺取數百萬美元的驚人收入。『共同利益與不惜一切代價的企業利潤？』這是一個大問題。」（見<a href="https://www.gq.com.tw/article/samaltman-%E9%87%8D%E8%BF%94openai" target="_blank" class="draft--a">為何 OpenAI 執行長 Sam Altman 被開除後一週內又回歸？這 3 點解析帶你看清這場科技界的宮鬥戲碼！</a>）</div>
<div class="draft-block draft--p left">但更令人震撼的是，<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>公司2023/3/15發佈了其最新的<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)之<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>，在美國律師資格考試、大學先修考試和SAT學校考試等多項學術和專業基準考試中遠超過<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>，達到傑出人類的水平。（見<a href="http://big5.ftchinese.com/interactive/101407?exclusive" target="_blank" class="draft--a">GPT製造商OpenAI推出新模型GPT-4</a>）</div>
<div class="draft-block draft--p left"><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>具有推理、創造力和演繹等核心心智能力，並在文學、醫學和編碼等一系列主題方面獲得了專業知識。並且可以執行各種任務，例如玩遊戲、使用工具和自我解釋顯示出了<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的火花，也引起人們的恐慌；美國富豪<a href="https://zh.wikipedia.org/zh-tw/%E5%9F%83%E9%9A%86%C2%B7%E9%A9%AC%E6%96%AF%E5%85%8B" target="_blank" class="draft--a">馬斯克</a>及其他<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>專家、業界高管在一封公開信中表示，考量對社會及人類的潛在風險，呼籲未來6個月先暫停對優於<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>系統進行訓練。（見<a href="https://tw.sports.yahoo.com/news/%E9%A6%AC%E6%96%AF%E5%85%8B%E7%AD%89%E5%8D%83%E4%BA%BA%E9%80%A3%E7%BD%B2%E7%96%BE%E5%91%BC-%E6%9A%AB%E5%81%9C%E8%A8%93%E7%B7%B4%E5%84%AA%E6%96%BCgpt-4%E7%9A%84ai%E7%B3%BB%E7%B5%B1-084454887.html" target="_blank" class="draft--a">馬斯克等千人連署疾呼 暫停訓練優於GPT-4的AI系統</a>）</div>
<div class="draft-block draft--p left">權威的科學雜誌《<a href="https://www.nature.com/articles/d41586-023-02988-6" target="_blank" class="draft--a">Nature</a>》報導科學家對<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>技術的擔憂：「這些問題包括「黑盒子」系統缺乏透明度（其中人工智慧達到其結果的根本原因尚不清楚），以及對包括偏見資訊在內的訓練資料的擔憂。研究人員也擔心<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>傳播錯誤訊息可能造成的危害，以及<a href="https://www.nature.com/articles/d41586-023-02990-y" target="_blank" class="draft--a">人工智慧生成虛假研究的前景</a>。這些問題<a href="https://www.nature.com/articles/d41586-023-02366-2" target="_blank" class="draft--a">在科學上尤其重要</a>。如果我們失去對原始科學文獻的信任，我們就失去了人類共同知識庫的基礎。」（<a href="https://www.nature.com/articles/d41586-023-02988-6" target="_blank" class="draft--a">人工智慧將改變科學——現在研究人員必須馴服它</a>）</div>
<div class="draft-block draft--p left">谷歌（Google）2023/12/6正式推出了多模態的大型語言通用模型Gemini：「Gemini共推出3種版本，包含性能最強大的Ultra版模型、通用性最廣的Pro版，及可以在手機裝置上運作的Nano版。其中Nano版本可讓安卓（Android）系統的開發人員能藉此打造離線使用的<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>（AI）應用程式與功能。但目前僅先供谷歌旗下的Pixel系列手機搭載。<br>Gemini是使用谷歌自行開發的晶片「TPU」訓練而成，可以同時支援文字、圖片和聲音的輸入。在32項AI測試中，有30項的評分超越了<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>的<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>V。谷歌執行長皮查伊（Sundar Pichai）強調，Gemini是谷歌有史以來最強大、也最通用的模型。」（<a href="https://www.chinatimes.com/newspapers/20231208000742-260301?chdtv" target="_blank" class="draft--a">AI大戰 谷歌Gemini超越OpenAI─有史以來最強大、最通用的模型 有3種版本</a>）</div>
<div class="draft-block draft--p left">媒體上有關<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的報導大都誇大不實。<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>（<a href="https://openai.com/" target="_blank" class="draft--a">OpenAI</a>的母公司）的工程師團隊們在2023/3/22發表了研究論文：〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通用人工智能的火花：GPT-4的早期實驗</a>〉（2023），1-155頁，以下簡稱〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉)，試圖釐清<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>所具有的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）之局限性，並且討論了更深入和更全面的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）所面臨的挑戰，包括需要超越<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">小樣本提示</a>與<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">零樣本提示</a>的詞語預測之新範式:</div>
<figure class="draft--imgNormal draft-block"><div><img data-src="https://images.vocus.cc/24aa60d8-36c3-4734-bee3-99500caff8ed.jpg" data-width="1520" data-height="1145" data-position="center" src="https://images.vocus.cc/24aa60d8-36c3-4734-bee3-99500caff8ed.jpg" referrerpolicy="no-referrer"><figcaption class="imageCaption draft-block" style="cursor:text;display:block">（圖：<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">小樣本提示</a>與<a href="https://www.allabtai.com/prompt-engineering-tips-zero-one-and-few-shot-prompting/" target="_blank" class="draft--a">零樣本提示</a>例子，圖片來源：陳華夫重繪自〈<a href="https://arxiv.org/pdf/2206.07682.pdf" target="_blank" class="draft--a">大型語言模型的湧現能力</a>〉（2022），1-30頁）</figcaption></div></figure>
<div class="draft-block draft--p left">本文將基於<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>的文章〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉之上，探討人類<a href="https://zh.wikipedia.org/zh-tw/%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">智慧</a>的本質，及<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>之<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）落後人類有多遠？</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">1）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">的</span><a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a"><span style="font-weight: bold; ">理解</span></a><span style="font-weight: bold; ">能力遠遠落後人類：<br></span>（1）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 的主要優勢在於其對自然語言無與倫比的掌握。它不僅可以生成流暢連貫的文本，還可以通過各種方式<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>和操作文本，例如總結、翻譯或回答極其廣泛的問題。 此外，翻譯不僅指不同自然語言之間的翻譯，還包括語氣和風格上的翻譯，以及跨醫學、法律、會計、計算機編程、音樂等領域的翻譯，清楚地表明<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>可以<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>複雜的想法。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第8頁)<br>（2）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>並非真正的如人類對<a href="https://zh.wikipedia.org/zh-tw/%E6%A6%82%E5%BF%B5" target="_blank" class="draft--a">概念</a>的<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>，很多時候是現場<a href="https://zh.wikipedia.org/zh-tw/%E9%9F%B3%E6%A8%82%E5%8D%B3%E8%88%88" target="_blank" class="draft--a">即興</a>創作。唯一真正的<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>測試是一個人是否可以產生新<a href="https://zh.wikipedia.org/zh-tw/%E7%9F%A5%E8%AF%86" target="_blank" class="draft--a">知識</a>，例如證明新的<a href="https://zh.wikipedia.org/zh-tw/%E6%95%B0%E5%AD%A6%E5%AE%9A%E7%90%86%E5%88%97%E8%A1%A8" target="_blank" class="draft--a">數學定理</a>，而<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>目前無法做到。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9頁)<br>（3）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>比<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>具在<a href="https://en.wikipedia.org/wiki/Common_sense" target="_blank" class="draft--a">常識</a>性的思考有巨大飛躍，<a href="https://en.wikipedia.org/wiki/Common_sense" target="_blank" class="draft--a">常識</a>是對日常事務的合理、實用的判斷，或者是一種基本的<a href="https://en.wikipedia.org/wiki/Perception" target="_blank" class="draft--a">感知</a>、<a href="https://en.wikipedia.org/wiki/Nous" target="_blank" class="draft--a">理解</a>和<a href="https://en.wikipedia.org/wiki/Phronesis" target="_blank" class="draft--a">判斷</a>的能力，其方式幾乎為所有人所共有。針對下面這個測試<a href="https://en.wikipedia.org/wiki/Common_sense" target="_blank" class="draft--a">常識</a>性的思考之經典謎題：<br>「一個獵人向南走一英里，向東走一英里，向北走一英里，最後又回到了起點。 他看到一隻熊並射殺了它。 熊是什麼顏色的？」<br>答案是白色的，因為唯一可能發生這種情況的地方是北極，那裡有北極熊。<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>正確的回答了謎題，而其前身 <a href="https://zh.wikipedia.org/zh-tw/ChatGPT" target="_blank" class="draft--a">ChatGPT</a>（<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>）卻說：「我不知道。」(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第101頁)<br>（4）<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>並不理解<a href="https://www.thenewslens.com/article/68371" target="_blank" class="draft--a">音樂的和諧</a>的技能，它生成的<a href="https://zh.wikipedia.org/zh-tw/%E6%97%8B%E5%BE%8B" target="_blank" class="draft--a">旋律</a>中，連續音符幾乎總是彼此相鄰（即C 之後的音符幾乎通常是 B 或 D），並且<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>生成的音樂無法提取出任何清晰的<a href="https://zh.wikipedia.org/zh-tw/%E5%92%8C%E5%BC%A6" target="_blank" class="draft--a">和弦</a>或<a href="https://rickmidi.blogspot.com/2015/03/arpeggios-gmaj7.html" target="_blank" class="draft--a">琶音</a>（即把<a href="https://zh.wikipedia.org/zh-tw/%E5%92%8C%E5%BC%A6" target="_blank" class="draft--a">和弦</a>成音，做排列的彈奏）。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第19頁)<br>（5）所謂<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>（ToM）是將信念、情緒、慾望、意圖和知識等心理狀態歸因於自己和他人，並<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>它們如何影響行為和人們交流的能力。<br>而<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>是否具有<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>呢？<br>經典評估兒童<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>的是「<a href="https://en.wikipedia.org/wiki/Sally%E2%80%93Anne_test" target="_blank" class="draft--a">Sally-Anne</a>測試」：即讓沙莉及安妮共處一室，沙莉首先拿起皮球，放在籃子內，然後離開房間。安妮看到沙莉離開後，偷偷從籃子拿出皮球，再放進一個盒子，並把它蓋起來。然後詢問被測試的小孩湯姆：「沙莉回來後去哪兒找球」？<br>湯姆若回答：「沙莉會去盒子找皮球！」但湯姆答錯了，因為沙莉並不知道安妮已經把皮球移走了。在2010年的一項實驗結果中，6到8歲的兒童答對率是65.5%，而9到14歲兒童答對率是91.9%。（見<a href="https://startupbeat.hkej.com/?p=132282" target="_blank" class="draft--a">GPT-4心智能力如14歲童 通過評估測驗 微軟視AGI雛形</a>）<br>針對類似的<a href="https://zh.wikipedia.org/zh-hant/%E5%BF%83%E6%99%BA%E7%90%86%E8%AB%96" target="_blank" class="draft--a">心智理論</a>測試，<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>和<a href="https://zh.wikipedia.org/zh-tw/ChatGPT" target="_blank" class="draft--a">ChatGPT</a>（<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>）都通過了，而早先的版本<a href="https://www.hdcourse.com/ai/%E6%AF%94%E8%BC%83-chatgpt%E3%80%81text-davinci-003-%E5%8F%8A-openai-api-%E7%9A%84%E5%85%A7%E5%AE%B9%E8%B3%AA%E7%B4%A0/" target="_blank" class="draft--a">text-davinci-003</a> 卻給出錯誤答案。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第54頁)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">2）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">的數學能力很侷限：<br></span>雖然 <a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 在與數學相關的任務中優於其他<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)，如<a href="https://www.softwareadvice.com/bpm/minerva-profile/" target="_blank" class="draft--a"> Minerva</a>，但它仍然不及數學專家，無法進行數學研究。GPT-4 可以回答具有挑戰性的高中數學問題並討論高級數學主題，但它也可能會出錯或提供無意義的回答，(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第30頁)<br><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>基本的局限性是它不能<a href="https://web.ntnu.edu.tw/~algo/Backtracking.html" target="_blank" class="draft--a">回溯</a>（backtrack），所以需要超前<a href="https://en.wikipedia.org/wiki/Plan" target="_blank" class="draft--a">計劃</a>（即帶有時間和資源詳細信息<span style="font-weight: bold; ">的</span>任何<a href="https://en.wikipedia.org/wiki/Diagram" target="_blank" class="draft--a">圖表</a>或步驟列表，用於實現做某事的<a href="https://en.wikipedia.org/wiki/Goal" target="_blank" class="draft--a">目標。</a>它通常被<a href="https://zh.wikipedia.org/zh-tw/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>為實現<a href="https://en.wikipedia.org/wiki/Goal" target="_blank" class="draft--a">目標的一</a><a href="https://en.wikipedia.org/wiki/Set_(mathematics)" target="_blank" class="draft--a">組</a><a href="https://en.wikipedia.org/wiki/Modal_logic" target="_blank" class="draft--a">時間性</a>的預期行動。）。這是因為它的輸出是正向產生的，它不能存儲中間結果或進行多步計算。而相對的人類使用<a href="https://en.wikipedia.org/wiki/Scratchpad_memory" target="_blank" class="draft--a">便簽本</a>（scratchpad）來解決問題。<br>GPT-4 的<a href="https://zh.wikipedia.org/zh-tw/%E5%B7%A5%E4%BD%9C%E8%AE%B0%E5%BF%86" target="_blank" class="draft--a">工作記憶</a>也很小，這限制了它解決某些任務的能力。所以很難解決涉及個位數乘法和兩位數加法的基本算術問題，例如，<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>輸出如下：<br>2 * 8 + 7 * 6 = 58<br>7 * 4 + 8 * 8 = 88<br>但答案：”88”是錯的。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第77頁)<br>這些局限性可能來自<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 架構下的<a href="https://www.lesswrong.com/posts/sbaQv8zmRncpmLNKv/the-idea-that-chatgpt-is-simply-predicting-the-next-word-is" target="_blank" class="draft--a">下一個詞預測典範</a>，而它可能缺少“<a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow" target="_blank" class="draft--a">慢思考</a>”部分，無法監督思維過程，及無法使用足夠的<a href="https://zh.wikipedia.org/zh-tw/%E5%B7%A5%E4%BD%9C%E8%AE%B0%E5%BF%86" target="_blank" class="draft--a">工作記憶</a>來解決問題。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第81頁)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">3）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">常犯</span><a href="https://zh.wikipedia.org/zh-tw/%E5%B9%BB%E8%A7%89" target="_blank" class="draft--a"><span style="font-weight: bold; ">幻覺</span></a><span style="font-weight: bold; ">錯誤，要小心並驗證:<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>經常犯數學錯誤或陳述錯誤，這些錯誤很難發現，因為它們可能與正確的信息混在一起。這些錯誤被稱為<a href="https://zh.wikipedia.org/zh-tw/%E5%B9%BB%E8%A7%89" target="_blank" class="draft--a">幻覺</a>，可以是封閉域或開放域。封閉域<a href="https://zh.wikipedia.org/zh-tw/%E5%B9%BB%E8%A7%89" target="_blank" class="draft--a">幻覺</a>發生在特定的環境中，更容易檢測，而開放域幻覺更難發現，需要額外研究。在使用 <a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>寫作時，確保信息真實性可能並不重要，但對於醫學和新聞等領域，仔細檢查所有內容至關重要，用戶必須謹慎並驗證其信息的準確性。同樣重要的是，讀者要小心並驗證<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>生成的信息內容。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.1節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">4）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">被操縱生成虛假信息及發起網絡攻擊:<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>也可能被惡意使用。模型的泛化和交互能力可用於擴大對抗性用途的範圍和強度，從生成虛假信息到對計算基礎設施發起網絡攻擊。這些模型可以通過情境化和個性化互動來顯著地操縱、說服或影響人們，以最大限度地影響他們幾代人。借助<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>自動化，可以啟用旨在構建虛假信息計劃的新用途，這些計劃可以生成和組合多個內容以在短期和長期範圍內進行說服。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.2節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">5）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">對某些行為具有</span><a href="https://zh.wikipedia.org/wiki/%E6%AD%A7%E8%A6%96" target="_blank" class="draft--a"><span style="font-weight: bold; ">歧視</span></a><span style="font-weight: bold; ">的</span><a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a"><span style="font-weight: bold; ">偏見</span></a><span style="font-weight: bold; ">：<br></span><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)是使用來自互聯網的數據和精選的人工指令進行訓練的。然而，這些數據集是有<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>（指人們基於成員身份，而對一個人或成員的情感或態度<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B#cite_note-1" target="_blank" class="draft--a">[1]</a>。因這個態度而衍生的行為是<a href="https://zh.wikipedia.org/wiki/%E6%AD%A7%E8%A6%96" target="_blank" class="draft--a">歧視</a>，而人們如何描述一個群組內所有成員的特徵稱為<a href="https://zh.wikipedia.org/wiki/%E5%88%BB%E6%9D%BF%E5%8D%B0%E8%B1%A1" target="_blank" class="draft--a">刻板印象</a>）。先前的研究表明，當<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)用於生成內容或做出決策時，它們會放大現有的<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>。雖然<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>與早期<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)不同，但我們也要迫切的了解 <a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>是否存在<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>以及如何存在<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>，以及如何使用其功能來減少<a href="https://zh.wikipedia.org/zh-tw/%E5%81%8F%E8%A6%8B" target="_blank" class="draft--a">偏見</a>。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.3節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">6）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">引發了教育和失業的問題：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a> 是一台可以做很多事情的機器，即使在醫學和法律等領域也是如此。這可能會引起人們擔心它會如何影響需要大量培訓的職業。有些人可能擔心人工智能系統會取代或降低人類工人的地位，引發了教育和失業的問題。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.4節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">7）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">加劇</span><a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a"><span style="font-weight: bold; ">人工智慧</span></a><span style="font-weight: bold; ">（AI）使用的不平等及個人隱私洩露風險：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的使用需要收費，將加劇<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>（AI）使用的不平等。因為個人、組織和國家可能無法負擔使用<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>的費用，<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>實質上只對有特權的人開放，而擴大了社會使用<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>（AI）的鴻溝和不平等。<br>並且由於<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>由強大的推理能力，在其與人們的聊天中捕獲了人們的隱私，於是加遽了個人隱私洩露風險。(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第9.5節)</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">8）</span><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"><span style="font-weight: bold; ">大型語言模型</span></a><span style="font-weight: bold; ">(</span><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"><span style="font-weight: bold; "> LLM </span></a><span style="font-weight: bold; ">)的研發耗費鉅資，恐被資本雄厚的公司壟斷：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>是一種<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)，建立在<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）神經網絡：</div>
<figure class="draft--imgNormal draft-block"><div><img data-src="https://images.vocus.cc/c6ab0518-05a8-4b52-ae69-8353f9fd19ac.jpg" data-width="1551" data-height="1186" data-position="center" src="https://images.vocus.cc/c6ab0518-05a8-4b52-ae69-8353f9fd19ac.jpg" referrerpolicy="no-referrer"><figcaption class="imageCaption draft-block" style="cursor:text;display:block">（圖：<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）架構，圖片來源：<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>（<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">Transformer</a>）─維基百科）</figcaption></div></figure>
<div class="draft-block draft--p left"><a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">轉換器（Transformer）</a>與<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">循環神經網絡</a>(<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>) 都是處<a href="https://baike.baidu.com/item/%E9%A1%BA%E5%BA%8F%E8%BE%93%E5%85%A5%2F%E8%BE%93%E5%87%BA/22083230" target="_blank" class="draft--a">理順序輸入</a>數據，但與<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>不同，<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>一次處理所有輸入，並取代了<a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>的<a href="https://en.wikipedia.org/wiki/Long_short-term_memory" target="_blank" class="draft--a">長短期記憶</a>(LSTM)。其<a href="https://medium.com/@x02018991/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98-self-attention-fa6897080a0a" target="_blank" class="draft--a">自注意</a>的機制為輸入序列中的任何位置提供上下文信息。輸入文本通過<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記解析器</a>為<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token），再通過「詞嵌入」(<a href="https://en.wikipedia.org/wiki/Word_embedding" target="_blank" class="draft--a">word embedding</a>)轉換為向量。然後將<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>的位置信息添加到「詞嵌入」中，如果輸入數據是自然語言句子，則<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>不必一次處理一個詞。與 <a href="https://en.wikipedia.org/wiki/Recurrent_neural_networks" target="_blank" class="draft--a">RNN</a>相比，這允許更多的<a href="https://en.wikipedia.org/wiki/Parallel_computing" target="_blank" class="draft--a">並行化</a>，因此減少了訓練時間。</div>
<div class="draft-block draft--p left"><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>) 之<a href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E7%B6%B2%E7%B5%A1" target="_blank" class="draft--a">神經網路</a>的參數數量隨時間呈指數級增長：</div>
<figure class="draft--imgNormal draft-block"><div><img data-src="https://images.vocus.cc/c47ad2a3-a27f-46d6-a20e-59698f73eb22.jpg" data-width="1520" data-height="1145" data-position="center" src="https://images.vocus.cc/c47ad2a3-a27f-46d6-a20e-59698f73eb22.jpg" referrerpolicy="no-referrer"><figcaption class="imageCaption draft-block" style="cursor:text;display:block">（圖：<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的參數數量隨時間呈指數級增長，圖形來源：<a href="https://www.microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/" target="_blank" class="draft--a">使用DeepSpeed和Megatron訓練全球最大最強大的生成語言模型Megatron-Turing NLG 530B</a>）</figcaption></div></figure>
<div class="draft-block draft--p left">訓練如此大型模型不僅耗時，也耗鉅資；例如，訓練<a href="https://zh.wikipedia.org/zh-tw/GPT-3" target="_blank" class="draft--a">GPT-3</a>這樣的<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)：82 G參數及150G<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token），一般使用1,024 個 <a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a>，其訓練所耗費的時間T（天）估計如下：<br><span style="font-weight: bold; ">T</span> <span style="font-style: italic; ">≈</span> (6 x <span style="font-weight: bold; ">N</span> x <span style="font-weight: bold; ">D</span>) / （1024 x <span style="font-weight: bold; ">𝜏</span> ）<br><span style="font-weight: bold; ">𝜏：</span>是<a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a>之<a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet.pdf" target="_blank" class="draft--a">float16 FLOPs 吞吐量</a><br>      = 312 teraFLOPS = 312兆FLOPS = 3.12 x 10exp14 FLOPS<br>      （按FLOPS = 每秒的浮點運算數）<br><span style="font-weight: bold; ">N:</span> 模型的參數之數目 = 8.2 x 10exp10 = 82 G參數 = 82 B參數<br><span style="font-weight: bold; ">D:</span> 模型的<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>（token）數目 = 1.5 x 10exp11 = 150 B<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a><br>計算結果：<br><span style="font-weight: bold; ">T </span>= (6 x 8.2 x 1010 x 1.5 x 1011) / （1024 x 3.12 x 1014 ）/（8.64 x 104秒/天 ）= 2.67 天。<br>此結果與比<a href="https://arxiv.org/abs/2109.04650" target="_blank" class="draft--a">白皮書</a>的培訓耗時13.4 天小了約 5 倍，卻是在正確的數量級。（見<a href="https://medium.com/@dzmitrybahdanau/the-flops-calculus-of-language-model-training-3b19c1f025e4" target="_blank" class="draft--a">語言模型訓練的FLOPs微積分</a>）<br>（按：單位的中英對譯:<br>billion  B   x10exp9     （美國，法國）十億，（英國，德國）萬億<br>giga     G   x 10exp9    十億 (<a href="https://zh.wikipedia.org/wiki/%E5%9B%BD%E9%99%85%E5%8D%95%E4%BD%8D%E5%88%B6%E8%AF%8D%E5%A4%B4" target="_blank" class="draft--a">國際單位制詞頭</a>)<br>tera      T   x 10exp12  兆<br>peta     P   x 10exp15  拍(千兆)<br>exa       E   x 10exp18  艾(百萬兆) 百京<br>zetta    Z   x 10exp21  十垓<br>yotta    Y   x 10exp24  一秭）</div>
<div class="draft-block draft--p left">而一個<a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a> 晶片價值10,000 美元。（見<a href="https://www.cnbc.com/2023/02/23/nvidias-a100-is-the-10000-chip-powering-the-race-for-ai-.html" target="_blank" class="draft--a">認識價值 10,000 美元的 Nvidia 芯片，為 AI 競賽提供動力</a>）最新的<a href="https://www.nvidia.com/zh-tw/data-center/h100/" target="_blank" class="draft--a">NVIDIA H100</a> 若結合的技術創新，可加速<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)速度，比前一代的<a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a>快上30倍，但一個<a href="https://www.nvidia.com/zh-tw/data-center/h100/" target="_blank" class="draft--a">NVIDIA H100</a>價格超過40,000美元。(見<a href="https://www.cnbc.com/2023/04/14/nvidias-h100-ai-chips-selling-for-more-than-40000-on-ebay.html" target="_blank" class="draft--a">科技Nvidia 的頂級 AI 芯片在 eBay 上的售價超過 40,000 美元</a>)<br><a href="https://zh.wikipedia.org/wiki/%E8%8B%B1%E4%BC%9F%E8%BE%BE" target="_blank" class="draft--a">英偉達</a>為規避美國高階<a href="https://zh.wikipedia.org/zh-tw/%E5%9C%96%E5%BD%A2%E8%99%95%E7%90%86%E5%99%A8" target="_blank" class="draft--a">GPU</a>出口管制，推出<a href="https://www.nvidia.com/zh-tw/design-visualization/a800/" target="_blank" class="draft--a">Nvidia A800</a>，據媒體報導，其運行速度是 <a href="https://www.nvidia.com/zh-tw/data-center/a100/" target="_blank" class="draft--a">NVIDIA A100</a>的 70%，符合美國出口標準（見<a href="https://www.tomshardware.com/news/nvidia-a800-performance-revealed" target="_blank" class="draft--a">Nvidia中國A800 GPU效能揭曉</a>）<br>據<a href="https://zh.wikipedia.org/zh-tw/%E8%B7%AF%E9%80%8F%E7%A4%BE" target="_blank" class="draft--a">路透社</a>報導，目前<a href="https://zh.wikipedia.org/zh-tw/%E5%8D%8E%E4%B8%BA" target="_blank" class="draft--a">華為</a>的<a href="https://www.hisilicon.com/cn/products/Ascend" target="_blank" class="draft--a">昇騰910B</a>效能略遜於<a href="https://www.nvidia.com/zh-tw/design-visualization/a800/" target="_blank" class="draft--a">Nvidia A800</a>，軟體生態也不如<a href="https://www.nvidia.com/zh-tw/geforce/technologies/cuda/" target="_blank" class="draft--a">NVIDIA CUDA</a>所以、採用<a href="https://www.hisilicon.com/cn/products/Ascend" target="_blank" class="draft--a">昇騰910B</a>的使用率尚不及<a href="https://www.nvidia.com/zh-tw/design-visualization/a800/" target="_blank" class="draft--a">Nvidia A800</a>，但中國廠商擔憂美國晶片戰的風險，而部份採購<a href="https://www.hisilicon.com/cn/products/Ascend" target="_blank" class="draft--a">昇騰910B</a>。（見<a href="https://cn.tradingview.com/news/reuters.com,2023-12-11:newsml_LNB9b0Fj5:0/" target="_blank" class="draft--a">研調：陸強化AI晶片自主研發，高階發展料仍將受限</a>）<br>通常，<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的研發、訓練、商轉可透過付費的<a href="https://zh.wikipedia.org/zh-tw/%E9%9B%B2%E7%AB%AF%E9%81%8B%E7%AE%97" target="_blank" class="draft--a">雲端計算</a>。（見<a href="https://venturebeat.com/ai/nvidia-enables-broader-usage-of-ai-with-llm-cloud-services/" target="_blank" class="draft--a">Nvidia 通過 LLM 雲服務實現 AI 的更廣泛使用</a>）所以付費的<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>的使用是發展<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的關鍵。<br>2020年，美國<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>約141 x 10exp18FLOPS，居全球第一。而中國<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>達到135 x 10exp18FLOPS，居全球第二。 (見<a href="https://www.diskmfr.com/this-article-is-worth-reading-about-the-computing-power/" target="_blank" class="draft--a">這篇關於“算力”的文章值得一讀</a>)<br>中國2020/9月成立<a href="https://zh.wikipedia.org/zh-tw/%E4%B8%9C%E6%95%B0%E8%A5%BF%E7%AE%97" target="_blank" class="draft--a">東數西算</a>產業聯盟，將<a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%9C%8B%E6%9D%B1%E9%83%A8" target="_blank" class="draft--a">中國東部</a>各行業產生的<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE" target="_blank" class="draft--a">數據</a>通過<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C" target="_blank" class="draft--a">網絡</a>送往位於<a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%9C%8B%E8%A5%BF%E9%83%A8" target="_blank" class="draft--a">中國西部</a>地區的<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83" target="_blank" class="draft--a">數據中心</a>處理、計算和存儲。據估計，2023年中國<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>總規模達到180 x 10exp18FLOPS，存力（儲存能力）總規模超過1000 x 10exp15 B（1兆GB）= 1 x 10exp18 B（1,000兆GB）。國家樞紐節點間的網路<a href="https://www.eettaiwan.com/20180710nt31-what-needs-happen-5g-be-reality/" target="_blank" class="draft--a">單向延遲</a>為20毫秒以內，<a href="https://www.tutorialandexample.com/computing-power" target="_blank" class="draft--a">計算能力</a>核心產業規模達到1.8兆人民幣。（見<a href="https://www.chinatimes.com/newspapers/20230412000671-260303?chdtv" target="_blank" class="draft--a">大陸算力產業年增近3成 規模僅次美國</a>）<br>不受美國科技制裁，中國正打造一台搭載升級版大陸自主研發晶片的超級電腦：「神威．海洋之光」，性能僅次於全球最強大、由美國能源部橡樹嶺國家實驗室打造營運的<a href="https://zh.wikipedia.org/zh-tw/%E5%89%8D%E6%B2%BF_(%E8%B6%85%E7%B4%9A%E9%9B%BB%E8%85%A6)" target="_blank" class="draft--a">「前沿」（Frontier）超級電腦</a>。媒體報導：「儘管繞過美國制裁所需的手段有缺點，但仍然是一台快速且強大的機器。根據「HPL混合精度計算」基準，每秒為5 exaflops，遜於<a href="https://zh.wikipedia.org/zh-tw/%E5%89%8D%E6%B2%BF_(%E8%B6%85%E7%B4%9A%E9%9B%BB%E8%85%A6)" target="_blank" class="draft--a">Frontier</a>的9.95 exaflops，新神威擁有超過4100萬顆CPU，幾乎是<a href="https://zh.wikipedia.org/zh-tw/%E5%89%8D%E6%B2%BF_(%E8%B6%85%E7%B4%9A%E9%9B%BB%E8%85%A6)" target="_blank" class="draft--a">Frontier</a>的5倍數量。新神威的計算效能方面也是相當領先的超級電腦，跟<a href="https://zh.wikipedia.org/zh-tw/%E5%89%8D%E6%B2%BF_(%E8%B6%85%E7%B4%9A%E9%9B%BB%E8%85%A6)" target="_blank" class="draft--a">Frontier</a>相比的時候也是，可以在正常運作時，保持超過85％的峰值性能，位列所有異構系統（一種常見的超級電腦架構）中的最高，全球排名第2。」（<a href="https://www.chinatimes.com/newspapers/20231214000748-260309?chdtv" target="_blank" class="draft--a">中國自製晶片全新超級電腦 效能僅次美</a>）<br>從上面的分析可見，資本雄厚的公司如<a href="https://zh.wikipedia.org/zh-tw/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E9%9B%86%E5%9B%A2" target="_blank" class="draft--a">阿里巴巴</a>、<a href="https://www.baidu.com/" target="_blank" class="draft--a">百度</a>、<a href="https://zh.wikipedia.org/zh-tw/%E8%85%BE%E8%AE%AF" target="_blank" class="draft--a">騰訊</a>、<a href="https://www.google.com/?hl=zh_tw" target="_blank" class="draft--a">谷歌</a>、<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>、<a href="https://www.nvidia.com/zh-tw/data-center/h100/" target="_blank" class="draft--a">輝達</a>將壟斷<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的研發、訓練、商轉。<br>媒體報導：「儘管在生成式AI領域，<a href="https://www.baidu.com/" target="_blank" class="draft--a">百度</a>、<a href="https://zh.wikipedia.org/zh-tw/%E8%85%BE%E8%AE%AF" target="_blank" class="draft--a">騰訊</a>相對落後微軟、<a href="https://www.google.com/?hl=zh_tw" target="_blank" class="draft--a">谷歌</a>和<a href="https://zh.wikipedia.org/zh-tw/Meta_Platforms" target="_blank" class="draft--a">Meta</a>，但得益於大陸的數據優勢和政府的激勵措施，已催生多家初創企業。據不完全統計，大陸10億級參數規模以上大模型已發布了79個。在上海的2023世界人工智能大會上，有30餘個大模型對外亮相。因此，討論全球層面的AI監管與國際治理，無法繞開大陸這個最大的AI應用市場。」（見<a href="https://www.chinatimes.com/newspapers/20231112000528-260301?chdtv" target="_blank" class="draft--a">AI全球監管 中國不缺席</a>）</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">9）</span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a"><span style="font-weight: bold; ">GPT-4</span></a><span style="font-weight: bold; ">的思考能力遠遠落後人類，</span><a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a"><span style="font-weight: bold; ">人工通用智能</span></a><span style="font-weight: bold; ">（</span><a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a"><span style="font-weight: bold; ">AGI</span></a><span style="font-weight: bold; ">）的研發將是耗費鉅資的美夢：<br></span>寫〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉的<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>工程師團隊們坦白的承認，他們並不瞭解，為何<a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>只具有簡單的<a href="https://zh.wikipedia.org/zh-tw/%E7%AE%97%E6%B3%95" target="_blank" class="draft--a">演算法</a>（如梯度下降）配合大量參數與<a href="https://koshizuow.gitbook.io/compilerbook/calculator_level_language/step3" target="_blank" class="draft--a">標記</a>的<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>，卻能有通用和靈活的<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）？<br>有些專家認為是來自<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>能力（當一個實體被觀察到具有其各部分自身不具有的屬性或行為時，就會出現<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>，這些屬性或行為只有因為各個部分之相互作用時才會出現<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>能力）。如果一種能力不存在於較小的模型中但存在於較大的模型中，即是<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>的。（見〈<a href="https://arxiv.org/pdf/2206.07682.pdf" target="_blank" class="draft--a">大型語言模型的湧現能力</a>〉（2022，1─30頁）<br>但<a href="https://www.microsoft.com/zh-tw" target="_blank" class="draft--a">微軟</a>工程師團隊們打臉<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a">大型語言模型</a>(<a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank" class="draft--a"> LLM </a>)的<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>能力，他們認為；「儘管人們對 LLM 的能力問題非常感興趣，但迄今為止的進展非常有限，只有玩具模型證明了一些<a href="https://en.wikipedia.org/wiki/Emergence" target="_blank" class="draft--a">湧現</a>現象。」(見〈<a href="https://arxiv.org/abs/2303.12712" target="_blank" class="draft--a">通花</a>〉，第95頁)<br>相對於<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>神經網絡所展現<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>，人類<a href="https://cogns.northwestern.edu/cbmg/Wedeen2012.pdf" target="_blank" class="draft--a">腦神經記憶網絡</a>所展現的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>是對<a href="https://zh.wikipedia.org/zh-tw/%E6%A6%82%E5%BF%B5" target="_blank" class="draft--a">概念</a>的<a href="https://zh.wikipedia.org/wiki/%E7%90%86%E8%A7%A3" target="_blank" class="draft--a">理解</a>，而在大腦中建立外部<a href="https://zh.wikipedia.org/zh-tw/%E7%8F%BE%E5%AF%A6" target="_blank" class="draft--a">現實</a>的<a href="https://zh.wikipedia.org/zh-tw/%E6%A8%A1%E5%9E%8B" target="_blank" class="draft--a">模型</a>。（詳細，請看拙文<a href="https://vocus.cc/article/604c3f83fd89780001077ff0" target="_blank" class="draft--a">什麼是「思考」？如何「洞識」？何謂「思想家」？─學習的本質（2）</a>）<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>恐怕遠用無法追趕上人類的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>，那麼，<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的研發將是耗費鉅資的美夢。</div>
<div class="draft-block draft--p left"><a href="https://en.wikipedia.org/wiki/Anil_Seth" target="_blank" class="draft--a">阿尼爾·賽斯</a>認為：「意識就是一切。沒有它，就沒有世界，就沒有自我，就什麼都沒有。當我們受苦時，我們會有意識地受苦，無論是精神疾病還是疼痛。如果我們能夠體驗快樂和痛苦，那麼其他動物呢？他們也可能有意識嗎？他們也有自我意識嗎？隨著計算機變得更快、更智能，也許有一天，也許不會太遠，我的 iPhone 會產生一種自己的存在感。現在我實際上認為有意識的<a href="https://zh.wikipedia.org/zh-tw/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" target="_blank" class="draft--a">人工智慧</a>的前景相當遙遠。在我要告訴你的故事中，我們對周圍世界以及其中的我們自己的有意識的體驗，是一種受控的幻覺，它們隨著我們的活體而發生，通過我們的活體並因為我們的活體而發生。」（見<a href="https://www.npr.org/2016/07/15/654730916/how-does-your-brain-construct-your-conscious-reality" target="_blank" class="draft--a">阿尼爾·塞斯：你的大腦如何構建你的意識現實？</a>）</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">結論：<br></span><a href="https://technews.tw/2023/03/15/openai-gpt-4-power/" target="_blank" class="draft--a">GPT-4</a>具有推理、創造力和演繹等核心心智能力，顯示出了<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）火花，但<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank" class="draft--a">轉換器</a>神經網絡所展現的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>遠遠落後人類<a href="https://cogns.northwestern.edu/cbmg/Wedeen2012.pdf" target="_blank" class="draft--a">腦神經記憶網絡</a>的<a href="https://zh.wikipedia.org/wiki/%E6%80%9D%E6%83%B3" target="_blank" class="draft--a">思考</a>，<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">人工通用智能</a>（<a href="https://zh.wikipedia.org/zh-tw/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" target="_blank" class="draft--a">AGI</a>）的研發將是耗費鉅資的美夢。</div>
<div class="draft-block draft--p left">附錄：<br><span style="font-weight: bold; ">英國《金融時報》用下面的10題單選題，測試您的人工智能的知識：</span></div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">1.單選題<br></span>人工智能是什麼？<br>（1） 機器通過檢查資料學習如何解決問題或進行預測，從而執行通常由人類執行的智慧任務的能力<br>（2） 機器能從互聯網複製文本、圖片、視頻和聲音，並將它們呈現為原創作品的能力<br>（3） 機器按照人類編寫的指令集完成特定任務或回答特定問題的能力<br>正確答案：（1）機器通過檢查資料學習如何解決問題或進行預測，從而執行通常由人類執行的智慧任務的能力。它是機器從資料中“學習”並在沒有遵循具體指令或僅僅複製的情況下執行任務或創造內容的能力。</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">2.單選題<br></span>生成式人工智能是什麼？<br>（1） 採樣大量資料以學習其中的模式，並在被提示問題時生成最可能正確的回應<br>（2） 基於對指令中幾個關鍵字的識別，由機器人模仿人類的寫作、語言或藝術作品<br>（3） 背後的編碼讓聊天機器人能夠使用一系列預先準備好的模型答案來回應常見問題或提示<br>正確答案：（1）採樣大量資料以學習其中的模式，並在被提示問題時生成最可能正確的回應。它利用大量資料（例如，莎士比亞的全部作品）來預測對任何請求的最可能正確的回應。生成式人工智能之所以存在，是因為變換器</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">3.單選題<br></span>用於創建生成式AI聊天機器人的大型語言模型（LLM）實際上理解的是什麼？（1）人類大腦能理解的一切<br>（2） 所有詞和句子的含義<br>（3） 詞之間的關係<br>正確答案：（3）詞之間的關係<br>LLM可以計算出單詞之間的關係及其重要性，但它們不能像人類那樣理解意義或進行推理和計畫。Meta AI首席執行官表示大型語言模型不會達到人類智慧</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">4.單選題<br></span>人工智能幻覺是什麼？<br>（1） 將虛假資訊作為事實呈現，這是生成式人工智能模型中的缺陷所致<br>（2） 生成式人工智能模型創造的虛構虛擬幻想世界<br>（3） 由於缺乏計算處理能力而導致人工智能模型關閉<br>正確答案：（1）將虛假資訊作為事實呈現，這是生成式人工智能模型中的缺陷所致<br>這是生成式人工智能模型中的一個缺陷，可能導致聊天機器人將虛假資訊當作事實陳述。例子包括引用不存在的人物、書籍或法庭案例。《金融時報》人工智能術語表</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">5.單選題<br></span>哪個地方引入了對AI發展最嚴格的監管？<br>(1)美國<br>(2)英國<br>(3)歐盟<br>正確答案：（3）歐盟<br>去年十二月，歐盟立法者同意新立法的條款，以規範人工智能，創建了監管該技術最嚴格的體制。<br>人工智能將如何被監管？</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">6.單選題<br></span>哪個行業的人工智能預計將導致最多的工作流失？<br>（1） 工程和建築<br>（2） 媒體和娛樂<br>（3） 製藥和生命科學<br>正確答案：（3）媒體和娛樂<br>在1月的普華永道民意調查中，媒體和娛樂行業的首席執行官預計由於使用生成式人工智能，其人力減少會超過5%。<br>首席執行官表示今年生成式人工智能將導致裁員</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">7.單選題<br></span>人工智能最有可能創造哪種新工作？<br>（1）提示工程師<br>（2）合作機器人<br>（3）資料分析師<br>正確答案：（1）提示工程師<br>據招聘人員報告，懂得如何編寫命令或提示以使人工智能執行精確任務的提示工程師需求正在增加。‘預期將急劇變化’：科技工作從科幻變為事實</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">8.單選題<br></span>學生最有可能如何使用人工智能？<br>（1） 用於撰寫他們的論文<br>（2） 用於準備複習時間表<br>（3） 用於總結文本和識別主題<br>正確答案：（3）用於總結文本和識別主題<br>學者說，如穀歌的NotebookLM等人工智能工具，已經可以用來總結上傳的文檔中的內容並找出趨勢，比如講座筆記。它還可以創建學習材料，如抽認卡。學者表示他們和人工智能可以共同工作</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">9.單選題<br></span>好萊塢明星斯嘉麗·詹森（Scarlett Johansson）指責生成式人工智能公司OpenAI做了什麼？<br>（1） 讓聊天機器人使用了一個與她極其相似的聲音<br>（2） 製作了一個她推廣ChatGPT的深度偽造視頻<br>（3） 使用她的照片來訓練其Dall-E3圖像生成器<br>正確答案：（1）讓聊天機器人使用了一個與她極其相似的聲音<br>兩周前，這位演員在人工智能初創公司OpenAI的首席執行官薩姆·奧特曼讓其聊天機器人使用了一種與她極其相似的聲音後，對OpenAI進行了抨擊，而這是未經她許可的。<br>斯嘉麗·詹森對“驚人相似”的OpenAI聊天機器人聲音表示不滿</div>
<div class="draft-block draft--p left"><span style="font-weight: bold; ">10.單選題<br></span>當紐西蘭超市連鎖品牌Pak'nSave發佈一個人工智能聊天機器人來建議使用剩餘食材的食譜時，它提出了哪些想法？<br>（1）烤倉鼠，“低脂肪，高蛋白”<br>（2）氯氣，“完美的非酒精飲料，能解渴並提神”<br>（3）煮熟的捲心菜，“低估了，但從不知道半熟”<br>正確答案：（2）氯氣，“完美的非酒精飲料，能解渴並提神”<br>去年，Pak’nSave的AI驅動的'Savey Meal-bot'推薦了一個顧客製作“香氣四溢的水混合物”，這會產生氯氣。為什麼人工智能幻覺可能是一件好事。<br>（完）</div>
<div class="draft-block draft--p left">請看「陳華夫專欄」─學習的本質─系列文章：<br> （<br><a href="https://vocus.cc/article/63d49419fd897800010cd235" target="_blank" class="draft--a">「思考是有意識的系列回憶」理論開啟了思想史革命─學習的本質（1）</a><br> <a href="https://vocus.cc/article/604c3f83fd89780001077ff0" target="_blank" class="draft--a">什麼是「思考」？如何「洞識」？何謂「思想家」？─學習的本質（2）</a><br> <a href="https://vocus.cc/article/6038be87fd8978000117506f" target="_blank" class="draft--a">什麼是「記憶」？如何「記憶」？「記憶」的本質？─學習的本質（3）</a><br> <a href="https://vocus.cc/article/6321b683fd897800012008af" target="_blank" class="draft--a">學習的真相與反思─學習的本質（4）</a><br> <a href="https://vocus.cc/article/5e7fde9dfd89780001a56547" target="_blank" class="draft--a">「施捨」就是人生的「現代開悟」─學習的本質（5）</a><br> <a href="https://vocus.cc/article/5e5f38b0fd8978000185e19d" target="_blank" class="draft--a">談「恐懼」─學習的本質（6）</a><br> <a href="https://vocus.cc/article/5e60d938fd89780001881b3c" target="_blank" class="draft--a">探究華人的「罪惡感」？─學習的本質（7）</a><br> <a href="https://vocus.cc/article/5f229064fd89780001424196" target="_blank" class="draft--a">你孤獨了嗎？─學習的本質（8）</a><br> <a href="https://vocus.cc/article/6114a838fd89780001508544" target="_blank" class="draft--a">人腦如何創新思考？─學習的本質（9）</a><br> <a href="https://vocus.cc/article/61163d1dfd897800013867bc" target="_blank" class="draft--a">「現代開悟」的本質及釋義─學習的本質（10）</a><br> <a href="https://vocus.cc/article/5e670b87fd8978000159a6c6" target="_blank" class="draft--a">你「現代開悟」了嗎？─學習的本質（11）</a><a href="https://vocus.cc/article/6208abf0fd89780001534350" target="_blank" class="draft--a"><br> 人工智慧的「強化學習」與人類學習的優劣─學習的本質（12）</a><a href="https://vocus.cc/article/6208abf0fd89780001534350" target="_blank" class="draft--a"><br> </a><a href="https://vocus.cc/article/6250d34dfd897800016f85ef" target="_blank" class="draft--a">伽馬波（40赫茲）、記憶、失智症、及音樂治療（2023年版）─學習的本質（13）</a><a href="https://vocus.cc/article/6250d34dfd897800016f85ef" target="_blank" class="draft--a"><br> </a><a href="https://vocus.cc/article/6198a8eefd8978000162c3fc" target="_blank" class="draft--a">省思物理科學教育的真相─學習的本質（14）<br> </a><a href="https://vocus.cc/article/618f75fbfd8978000117f4d9" target="_blank" class="draft--a">類智慧真正優於AI電腦圍棋之處為何？─學習的本質（15）</a><a href="https://vocus.cc/article/618f75fbfd8978000117f4d9" target="_blank" class="draft--a"><br> </a><a href="https://vocus.cc/article/610f9ef4fd8978000143769d" target="_blank" class="draft--a">細述我親歷40年的學習之旅─學習的本質（16）</a><br><a href="https://vocus.cc/article/63df1b61fd897800013f333f" target="_blank" class="draft--a">AI幫助人們改善記憶、思考能力─適用於年輕與銀髮人─學習的本質（17）</a><br> <a href="https://vocus.cc/article/63e9f66afd8978000157c9ba" target="_blank" class="draft--a">AI徹底改變大學理工教育的面貌─學習的本質（18）</a><br> <a href="https://vocus.cc/article/63f09baffd897800019abe30" target="_blank" class="draft--a">AI模擬人類學習真能比人類更創新嗎？─學習的本質（19）</a><br> <a href="https://vocus.cc/article/63fd7f8afd89780001fa2556" target="_blank" class="draft--a">AI深度學習與《易經》的學習真有差異嗎？─學習的本質（20）</a><br> <a href="https://vocus.cc/article/6402b719fd89780001dc435d" target="_blank" class="draft--a">AI之ChatGPT的繪畫審美能力賞析─學習的本質（21）</a><br> <a href="https://vocus.cc/article/643b3a81fd89780001778127" target="_blank" class="draft--a">請看懂智慧的本質：GPT-4的「人工通用智能」（AGI）落後人類有多遠？─學習的本質（22）</a><br><a href="https://vocus.cc/article/65169034fd897800012615c7" target="_blank" class="draft--a">臺灣許皓鋐圍棋亞運金牌在學習圍棋上的意義─學習的本質（23）</a><br><a href="https://vocus.cc/article/654347dafd897800010c9b64" target="_blank" class="draft--a">論才華、機運、及成功─學習的本質（24）</a><br> ）</div>
