---
layout: post
title: "【美麗新世界？】中國發展情緒辨識技術　《環時》指可用於「反恐」"
date: 2021-03-05 09:25:33.000000000 +00:00
link: https://thestandnews.com/technology/%E7%BE%8E%E9%BA%97%E6%96%B0%E4%B8%96%E7%95%8C-%E4%B8%AD%E5%9C%8B%E7%99%BC%E5%B1%95%E6%83%85%E7%B7%92%E8%BE%A8%E8%AD%98%E6%8A%80%E8%A1%93-%E7%92%B0%E6%99%82-%E6%8C%87%E5%8F%AF%E7%94%A8%E6%96%BC-%E5%8F%8D%E6%81%90/
categories: stand
tags: blog
author: 立場報道
---

<img width="600" src="https://images.weserv.nl/?url=cdn.thestandnews.com/media/photos/cache/emotion-18_jyYgr_600x0.png" /><br /><br /><p>人類情感難以理解，但人工智能近年越趨成熟，用電腦辨別人類情緒也不再是天方夜譚。而在中國，辨識人民情緒的技術更是蓬勃發展，更可能成為中國「反恐」的武器。</p>
<p>人工智能可否「理解」人類情感是深奧的科學及哲學問題，但可以肯定的是，辨別情緒已非難事。新研發的人工智能演算法聲稱已可透過影像，或者是量度其他生理反應，例如肌肉活動、心跳、呼吸，甚至是聲調等，辨識出一個人的喜怒哀樂。</p>
<p>中國近年投資大量資源於人工智能領域，中國官媒《環球時報》引述專研人工智能科技的「翼開科技」負責人魏清晨指，部份演算法的準確度甚至達 70–95% 。寧波大學神經經濟及管理學教授馬慶國則表示，「情緒辨識絕對是人類未來科技發展的方向。」</p>
<p>表面看來，準確的情緒辨識技術可應用於不同範疇，如保安系統、駕駛科技或智能家居系統等。《環球時報》指，翼開科技其中一個情緒辨識演算法，已可用於辨識精神分裂症患者，並稱準確度達 78.8% ，接近臨床標準測試表現。公司負責人魏清晨更指，即使單以聲音，該公司的演算法都可用作辨識抑鬱症患者，準確度約 70%。</p>
<p><strong>欠缺私隱法律規範</strong></p>
<p>但與絕大部份人工智能系統一樣，情緒辨識技術同樣需收集大量個人敏感資訊，衍生出私隱以至人權問題。在中國研發人工智能系統的深圳太古計算機有限公司總經理陳偉便對《衞報》承認，中國現時的情緒辨識技術之所以可以蓬勃發展，是因為當地欠缺嚴格私隱法律規範，當局基本上可全無限制下，以國家安全或者公共安全為名，取得生物特徵數據。「因此，一我們有機會不斷收集數據，並找出最佳使用數據的方法。」</p>
<p>不過，中國智庫組織似乎並不擔心。智庫數字經濟行政院長黃日涵就對《環球時報》指，可透過監管個人數據收集及披露，改善公民私隱問題，政府亦可加強督導。</p>
<p>在監控已是常態的中國，這類科技有機會被會用作打壓異見人士或少數族裔的工具。《環球時報》更直白地指出，中國已將情緒辨識技術，廣泛應用於反恐及市區治安等。陳偉就對《衞報》承認：「一般中國人都對這種新科技（情緒辨識）感到不快，但他們沒有選擇。如果公安要在社區內安裝監視器，人們只能接受。」</p>
<p>新疆維族被北京視為國內不穩定源頭之一，當局也多番以反恐、扶貧為由，對新疆維族人諸多監控。在新科技冒起下，維族人也自然成為人工智能系統的「白老鼠」。早年《紐約時報》曾報道，指<a href="https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html" target="_blank">當地有科技公司為政府研發了可用作追蹤新疆維族人的人工智能系統</a>。美國一些智庫組織調查也顯示，<a href="https://www.thestandnews.com/china/%E8%8F%AF%E7%82%BA%E5%B0%88%E5%88%A9%E6%8F%90%E5%8F%8A%E8%AD%98%E5%88%A5%E7%B6%AD%E5%90%BE%E7%88%BE%E6%97%8F%E4%BA%BA-ai-%E6%8A%80%E8%A1%93/" target="_blank">華為、商湯科技及曠視科技等文件都曾透露技術可用於辨別維族人口</a>。</p>
<p><strong>人權組織：將被用作恐嚇、審查</strong></p>
<p>陳偉則對情緒辨識科技持正面態度，他對《衞報》指：「拘留中心時有暴力或自殺⋯⋯即使現在警察已不會打人，但也有機會不淮被拘留人士睡覺。因此，部份囚犯會出現精神崩潰情況，並企圖自殺。而我們的系統則可阻止這些情況發生。」他亦舉例指，這些系統可用作避免暴力事件發生。</p>
<p>不過，英國人權組織 Article 19 的數碼計劃經理 Vidushi Marda 就反駁，「當嶄新的科技以安全或保安為名攞出時，這是常用，以及有點令人氣餒的論述。」Marda 指出，現實影片監控對於安全沒甚麼連繫，坦言：「我不肯定他們怎樣認為（系統）即時結果會怎樣解決暴力問題。」他直指生物監控技術更多是與恐嚇或者審查有關，而情緒辨識科技就是其中一種。</p>
<p>魏清晨就對《環時》指，情緒辨識運算不是「邪惡讀心技術」，並指中國企業將「嚴謹遵從『科技向善』原則，以為人民服務及不讓人逍遙法外為目標使用科技。」 </p>
<p>來源：<a href="https://www.globaltimes.cn/page/202103/1217212.shtml?fbclid=IwAR1aWxYtLgZvgXh0IMI5Ry7LuqUdJujN-NTKQqaAP3Lwmf5d5zDskmkj7eU" target="_blank">環球時報</a>, <a href="https://www.theguardian.com/global-development/2021/mar/03/china-positive-energy-emotion-surveillance-recognition-tech" target="_blank">衛報</a>, <a href="https://nypost.com/2021/03/04/china-using-emotion-recognition-technology-in-surveillance/" target="_blank">紐約郵報</a></p>
