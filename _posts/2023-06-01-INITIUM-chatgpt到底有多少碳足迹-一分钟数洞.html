---
layout: post
title: ChatGPT到底有多少碳足迹？｜一分钟数洞
date: 2023-06-01 02:58:00.000000000 +00:00
link: https://theinitium.com/article/20230602-dataphile-carbon-footprint-of-chatgpt/
categories: initium
tags: blog
author: 特约撰稿人 徐彦颀
---

<p>「训练 ChatGPT产生的碳排放，相当于你乘经济舱在北京香港之间飞行一千多次」</p><p>特约撰稿人 徐彦颀</p><figure class="image" itemscope itemtype="https://schema.org/ImageObject"><a class="image" href="https://theinitium.com/article/20230602-dataphile-carbon-footprint-of-chatgpt/undefined"><img src="https://d32kak7w9u5ewj.cloudfront.net/media/image/2023/06/de9eed45a5284cd3921f4b9ebd615e6d.png?imageView2/1/w/1080/h/720/format/jpg" alt itemprop="contentUrl" referrerpolicy="no-referrer"></a>
            <figcaption itemprop="caption"><span class="credit"></span></figcaption></figure><p><strong>（徐彦颀：一名用数据看世界的社会新闻记者）</strong></p>
<p>2023年是生成式人工智能系统（Generative AI）大爆发的一年：你肯定听过大型语言模型（LLM；Large Language Models）ChatGPT﹑Claude﹑Bard﹑Dragonfly；生成图像的人工智能程式Midjourney﹑Dall-E﹑Stable Diffusion等。自2022年尾的ChatGPT问世以来，各个科技公司纷纷推出了其他大型语言模型；许多人都在关注这场技术革命对人类社会带来的影响，和可能牵涉的法规和道德问题－－但其实碳排可能也是这些演算法带来的问题之一。</p>
<p>目前GPT等人工智能迅速更新换代不仅带来数据量的演变，还有与已有平台和服务的融合，譬如Bing 和Duolingo已搭载GPT-4，而其服务器遍布世界各地，使得测算其碳排放难上加难。我下载了微软的Edge浏览器，问了问Bing Chat，却并没有得到直接相关的答案，倒是得知根据牛津大学2015年的一份报告，每一次谷歌搜索大致相当于0.2公克的碳排放。</p>
<p>相比而言，这些模型的训练过程的碳足迹相对而言比较容易计算。单纯训练的过程，已可窥其排放之体量。</p>
 
 
 
 

 
 
 
 
 
 
 
 
<p>要训练出像ChatGPT这样的大型语言模型，需要向模型输入海量文本，再不断根据结果调整模型的参数和权重。开发者们在GPT-3的训练阶段交给了它570GB的文本数据进行学习，包括大把书籍和网络文章、维基百科界面等等。其中包括3000亿个单词。ChatGPT能够灵活自然语言运用，是因为开发人员在训练过程中不断调整其1750亿的训练参数（parameters）。</p><p>ChatGPT就是基于GPT-3稍作优化后的3.5版本推出的。其庞大数据量并不是独一家。类似的BLOOM模型（全称为The BigScience Large Open-science Open-access Multilingual Language Model)就训练了一年之久，涵盖了1760亿参数，其训练集使用了1.6TB的数据，在46门自然语言和13种编程语言中测试。</p><p>一篇研究报告估测，Gopher和GPT-3机器学习单单在模型训练过程中就高达百吨，其中GPT-3位居榜首，预估排放502吨二氧化碳。这大约相当于62倍中国人均年度碳排放。根据国泰航空碳足迹计算公式估算，可以让一位从北京到香港的经济舱旅客来回飞行1394次。</p><p><a class="image" href="https://theinitium.com/article/20230602-dataphile-carbon-footprint-of-chatgpt/undefined"><img src="https://d32kak7w9u5ewj.cloudfront.net/media/image/2023/06/51042ea941384da79945de4e3c1d214a.png?imageView2/1/w/1080/h/1350/format/jpg" alt itemprop="contentUrl" referrerpolicy="no-referrer"></a>
            </p><figcaption itemprop="caption"><span class="credit"></span></figcaption><p></p><p>类似ChatGPT之类的语言模型的碳排放和几个因素有关：其一是在模型学习训练集过程中调试中的参数数量（其中大部分模型以数千亿计），其二是研发模型公司的实体数据中心的能耗，其中包括电脑的运行以及空调的能耗等等，其三则是碳浓度，与数据中心当地获得电力的方式有关。</p><p>但训练过程仅是大型LLM运作的一个方面，后续还有云端部署等步骤。在你和ChatGPT“交谈”的时候，GPU,CPU以及RAM都在工作。在2023年1月，ChatGPT就收到了5.9亿次访问。丹麦数据科学家Kasper Groes Albin Ludvigsen认为其所需的GPU很有可能达到两万多个，这也这意味著其分布的区域也十分多样，很难测算其碳排放。</p><p>他认为单就今年一月所使用的电量而言，ChatGPT达到110万到2300万千瓦时。110万千瓦时约为2243个中国人月用电量。这个电量按照世界范围内平均每千瓦时475克的碳排放计算，则相当于522吨碳排放。</p><p>同一篇报告预测BLOOM产品周期主要三个步骤中的器材制造、学习训练和部署运作就达到50吨碳排放，约为训练过程的两倍。此预测仍然不含处理器原料的获取与提炼，以及后续的硬件更迭和报废处理。</p><p>在实验中每次BLOOM搜索平均的能耗则为3.96瓦时，大约等于给智能手机供电到20%的电量。以同样的全球平均碳排能效计算，大约相当于1.81克二氧化碳，略微小于10倍单次谷歌搜索，虽然ChatGPT很有可能小于这个数值。</p><p>我又问了谷歌公司的人工智能BARD同样的问题，它给出的答案是ChatGPT和GPT-4每一次搜索能耗不高，仅在0.01-0.02克之间。</p><p>另一家法国公司Greenly则估测ChatGPT-3(第三代）的碳排放在每年238吨左右。而其中，以电力为主（160吨），68.9吨来自服务器，9.6吨来自空调。</p><p>这些测算都是基于ChatGPT-3（三代），而现已经更迭到第四代的GPT-4囊括的是更新的数据，更大的访问量，和极有可能更多的排放。</p><p>出于好奇，我使用Bing Chat 问了GPT-4单次搜索相当的碳排放，但始终没有得到任何有意义的答案。联想到我每一次问这个问题可能产生的环境污染，我关闭了这个界面。</p>
